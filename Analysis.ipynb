{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"OSX\"\n"
     ]
    }
   ],
   "source": [
    "# Function to check the operating system\n",
    "check_os <- function() {\n",
    "  sys_info <- Sys.info()\n",
    "  os <- sys_info['sysname']\n",
    "  \n",
    "  if (os == \"Darwin\") {\n",
    "    return(\"OSX\")\n",
    "  } else if (os == \"Windows\") {\n",
    "    return(\"Windows\")\n",
    "  } else {\n",
    "    return(\"Other\")\n",
    "  }\n",
    "}\n",
    "\n",
    "if (check_os() == \"OSX\") {\n",
    "    print(\"OSX\")\n",
    "    setwd('/Users/fareedsuri/SynologyDrive/Data/CarotidData2023')\n",
    "    Sys.setenv(RETICULATE_PYTHON = '/usr/local/bin/python3')\n",
    "} else if (check_os() == \"Windows\") {\n",
    "    print(\"Windows\")\n",
    "    setwd('E:/SynologyDrive/Data/CarotidData2023')\n",
    "    Sys.setenv(RETICULATE_PYTHON = \"C:\\\\Users\\\\fsuri\\\\Anaconda3\")\n",
    "} else { \n",
    "    print(\"Unknown OS\")\n",
    "}\n",
    "\n",
    "folder<-'Analysis'\n",
    "# Example usage\n",
    "# os_type <- check_os()\n",
    "# print(os_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages('IRkernel')\n",
    "# IRkernel::installspec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"remotes\")\n",
    "# install.packages(\"lintr\")\n",
    "# install.packages(\"vscDebugger\")\n",
    "# remove.packages(\"lintr\")\n",
    "# # lintr::use_lintr(type = \"tidyverse\")\n",
    "# install.packages(\"reshape2\")\n",
    "# install.packages(\"glue\")\n",
    "# install.packages(\"svglite\")\n",
    "# install.packages(\"rsvg\")\n",
    "# update.packages(ask = FALSE,c(\"ggplot2\"))\n",
    "# install.packages(\"vscDebugger\")\n",
    "# install.packages(\"ggpattern\")\n",
    "# install.packages(c(\"rmarkdown\",\"knitr\",\"xfun\"))\n",
    "# install.packages(\"interactions\")\n",
    "# install.packages(\"reghelper\")\n",
    "# install.packages('sandwich')\n",
    "# install.packages('reticulate')\n",
    "# install.packages('writexl')\n",
    "# install.packages('readxl')\n",
    "# install.packages('officer')\n",
    "# install.packages('vscDebugger')\n",
    "# install.packages('gtsummary')\n",
    "# install.packages(\"languageserver\")\n",
    "# remove.packages(\"languageserver\")\n",
    "# install.packages('ggplot2')\n",
    "# install.packages('tidyverse')\n",
    "# install.packages('survminer')\n",
    "# install.packages('flextable')\n",
    "# install.packages('tables')\n",
    "# install.packages('crosstable')\n",
    "# install.packages('crosstable')\n",
    "# install.packages('caret')\n",
    "# install.packages(\"devtools\")\n",
    "# install.packages(\"roxygen2\")\n",
    "# install.packages('flextable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/latex": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/markdown": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/plain": [
       "[1] \"/Users/fareedsuri/SynologyDrive/Data/CarotidData2023\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'R version 4.4.0 (2024-04-24)'"
      ],
      "text/latex": [
       "'R version 4.4.0 (2024-04-24)'"
      ],
      "text/markdown": [
       "'R version 4.4.0 (2024-04-24)'"
      ],
      "text/plain": [
       "[1] \"R version 4.4.0 (2024-04-24)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sessionInfo()\n",
    "R.version.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# library(vscDebugger)\n",
    "library(reticulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(paste0(getwd(),'/gtsummary'),repos=NULL,type=\"source\",lib=paste0(getwd(),'/gtsummary'))\n",
    "# library(gtsummary, lib.loc = paste0(getwd(),'/gtsummary'))\n",
    "# install.packages('tidymodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- \u001b[1mAttaching core tidyverse packages\u001b[22m ------------------------ tidyverse 2.0.0 --\n",
      "\u001b[32mv\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32mv\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32mv\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32mv\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32mv\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32mv\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32mv\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32mv\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "-- \u001b[1mConflicts\u001b[22m ------------------------------------------ tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mi\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "Linking to librsvg 2.56.3\n",
      "\n",
      "\n",
      "Attaching package: 'jsonlite'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    flatten\n",
      "\n",
      "\n",
      "Loading required package: carData\n",
      "\n",
      "\n",
      "Attaching package: 'car'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    recode\n",
      "\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    some\n",
      "\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    lift\n",
      "\n",
      "\n",
      "-- \u001b[1mAttaching packages\u001b[22m -------------------------------------- tidymodels 1.2.0 --\n",
      "\n",
      "\u001b[32mv\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.6      \u001b[32mv\u001b[39m \u001b[34mrsample     \u001b[39m 1.2.1 \n",
      "\u001b[32mv\u001b[39m \u001b[34mdials       \u001b[39m 1.2.1      \u001b[32mv\u001b[39m \u001b[34mtune        \u001b[39m 1.2.1 \n",
      "\u001b[32mv\u001b[39m \u001b[34minfer       \u001b[39m 1.0.7      \u001b[32mv\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.4 \n",
      "\u001b[32mv\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.3.0      \u001b[32mv\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.1.0 \n",
      "\u001b[32mv\u001b[39m \u001b[34mparsnip     \u001b[39m 1.2.1      \u001b[32mv\u001b[39m \u001b[34myardstick   \u001b[39m 1.3.1 \n",
      "\u001b[32mv\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.10     \n",
      "\n",
      "-- \u001b[1mConflicts\u001b[22m ----------------------------------------- tidymodels_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m        masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m          masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m         masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31mx\u001b[39m \u001b[34mjsonlite\u001b[39m::\u001b[32mflatten()\u001b[39m      masks \u001b[34mpurrr\u001b[39m::flatten()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m             masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31mx\u001b[39m \u001b[34mcaret\u001b[39m::\u001b[32mlift()\u001b[39m            masks \u001b[34mpurrr\u001b[39m::lift()\n",
      "\u001b[31mx\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mprecision()\u001b[39m   masks \u001b[34mcaret\u001b[39m::precision()\n",
      "\u001b[31mx\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mrecall()\u001b[39m      masks \u001b[34mcaret\u001b[39m::recall()\n",
      "\u001b[31mx\u001b[39m \u001b[34mcar\u001b[39m::\u001b[32mrecode()\u001b[39m            masks \u001b[34mdplyr\u001b[39m::recode()\n",
      "\u001b[31mx\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32msensitivity()\u001b[39m masks \u001b[34mcaret\u001b[39m::sensitivity()\n",
      "\u001b[31mx\u001b[39m \u001b[34mcar\u001b[39m::\u001b[32msome()\u001b[39m              masks \u001b[34mpurrr\u001b[39m::some()\n",
      "\u001b[31mx\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m        masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31mx\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspecificity()\u001b[39m masks \u001b[34mcaret\u001b[39m::specificity()\n",
      "\u001b[31mx\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m          masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m*\u001b[39m Search for functions across packages at \u001b[32mhttps://www.tidymodels.org/find/\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(readxl)\n",
    "library(ggplot2)\n",
    "library(ggpattern)\n",
    "library(tidyverse)\n",
    "library(gt)\n",
    "library(glue)\n",
    "library(svglite)\n",
    "library(rsvg)\n",
    "library(jsonlite)\n",
    "library(writexl)\n",
    "library(car)\n",
    "library(caret)\n",
    "library(tidymodels)\n",
    "# library(gtsummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'reshape2'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    smiths\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(reshape2)\n",
    "library(interactions)\n",
    "library(sandwich)\n",
    "library(tidymodels)\n",
    "# library(reghelper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'survival'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:caret':\n",
      "\n",
      "    cluster\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggpubr\n",
      "\n",
      "\n",
      "Attaching package: 'survminer'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:survival':\n",
      "\n",
      "    myeloma\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "You have loaded plyr after dplyr - this is likely to cause problems.\n",
      "If you need functions from both plyr and dplyr, please load plyr first, then dplyr:\n",
      "library(plyr); library(dplyr)\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Attaching package: 'plyr'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:ggpubr':\n",
      "\n",
      "    mutate\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:dplyr':\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    compact\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'flextable'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:ggpubr':\n",
      "\n",
      "    border, font, rotate\n",
      "\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    compose\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'crosstable'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:plyr':\n",
      "\n",
      "    compact\n",
      "\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    compact\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'rlang'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:jsonlite':\n",
      "\n",
      "    flatten, unbox\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:purrr':\n",
      "\n",
      "    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n",
      "    flatten_raw, invoke, splice\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'officer'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:readxl':\n",
      "\n",
      "    read_xlsx\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(survival)\n",
    "library(survminer)\n",
    "library(dplyr) # %>%\n",
    "library(plyr)\n",
    "library(flextable)\n",
    "library(tables)\n",
    "library(crosstable)\n",
    "library(IRdisplay)\n",
    "library(rlang)\n",
    "library(officer)\n",
    "library(haven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(officer)\n",
    "disp <- IRdisplay::display_html\n",
    "set_flextable_defaults(\n",
    "  font.family = \"Open Sans\",\n",
    "  font.size = 10, \n",
    "  theme_fun = theme_vanilla,\n",
    "  padding = 6,\n",
    "  background.color = \"#EFEFEF\")\n",
    "set_flextable_defaults(\n",
    "  digits = 2,\n",
    "  decimal.mark = \".\",\n",
    "  big.mark = \",\",\n",
    "  na_str = \".\" \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>python3:</strong> '/Library/Frameworks/Python.framework/Versions/3.12/bin/python3'"
      ],
      "text/latex": [
       "\\textbf{python3:} '/Library/Frameworks/Python.framework/Versions/3.12/bin/python3'"
      ],
      "text/markdown": [
       "**python3:** '/Library/Frameworks/Python.framework/Versions/3.12/bin/python3'"
      ],
      "text/plain": [
       "                                                         python3 \n",
       "\"/Library/Frameworks/Python.framework/Versions/3.12/bin/python3\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.which(\"python3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: usethis\n",
      "\n",
      "\n",
      "Attaching package: 'devtools'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:recipes':\n",
      "\n",
      "    check\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'MASS'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    select\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(devtools)\n",
    "library(roxygen2)\n",
    "library(MASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Install and load the necessary packages\n",
    "# if (!requireNamespace(\"devtools\", quietly = TRUE)) {\n",
    "#   install.packages(\"devtools\")\n",
    "# }\n",
    "# if (!requireNamespace(\"tf\", quietly = TRUE)) {\n",
    "#   devtools::install_github(\"E:/SynologyDrive/Data/CREST/CREST_ANALYSIS/tf\")  # Replace \"someuser/tf\" with the actual GitHub repository for the \"tf\" package\n",
    "# }\n",
    "# if (!requireNamespace(\"tidyfun\", quietly = TRUE)) {\n",
    "#   devtools::install_github(\"E:/SynologyDrive/Data/CREST/CREST_ANALYSIS/tidyfun\")  # Replace \"someuser/tidyfun\" with the actual GitHub repository for the \"tidyfun\" package\n",
    "# }\n",
    "# library(tidyfun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/latex": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/markdown": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/plain": [
       "[1] \"/Users/fareedsuri/SynologyDrive/Data/CarotidData2023\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m\u001b[36mi\u001b[39m Loading \u001b[34mgtsummary\u001b[39m\n",
      "#BlackLivesMatter\n",
      "\n",
      "\u001b[1m\u001b[22m\u001b[36mi\u001b[39m Loading \u001b[34mbroom\u001b[39m\n",
      "\u001b[1m\u001b[22m\u001b[36mi\u001b[39m Loading \u001b[34mbroom.helpers\u001b[39m\n",
      "\u001b[1m\u001b[22m\u001b[36mi\u001b[39m Loading \u001b[34mofficer\u001b[39m\n",
      "\u001b[1m\u001b[22m\u001b[36mi\u001b[39m Loading \u001b[34mflextable\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# devtools::load_all(\"E:/SynologyDrive/Data/CREST/CREST_ANALYSIS/tidyfun\",TRUE)\n",
    "rm(list = c(\"as_flextable\",\"keep_with_next\"))\n",
    "path_ <- paste0(getwd(),\"/\",folder)\n",
    "devtools::load_all(paste0(path_,\"/gtsummary\"),TRUE)\n",
    "devtools::load_all(paste0(path_,\"/broom\"),TRUE)\n",
    "devtools::load_all(paste0(path_,\"/broom.helpers\"),TRUE)\n",
    "devtools::load_all(paste0(path_,\"/officer\"),TRUE)\n",
    "devtools::load_all(paste0(path_,\"/flextable\"),TRUE)\n",
    "# devtools::load_all(\"E:/Synol\"ogyDrive/Data/CREST/CREST_ANALYSIS/pracma\",TRUE)\n",
    "# devtools::load_all(\"E:/SynologyDrive/Data/CREST/CREST_ANALYSIS/ggstats\",TRUE)\n",
    "# devtools::load_all(\"E:/SynologyDrive/Data/CREST/CREST_ANALYSIS/ggally\",TRUE)\n",
    "# devtools::load_all(\"E:/SynologyDrive/Data/CREST/CREST_ANALYSIS/tf\",TRUE)\n",
    "\n",
    "\n",
    "# devtools::test()\n",
    "# devtools::check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## return the names of the objects (from a vector of list of\n",
    "## names of objects) that are functions and have debug flag set\n",
    "isdebugged_safe <- function(x,ns=NULL)  {\n",
    "    g <- if (is.null(ns)) get(x) else getFromNamespace(x,ns)\n",
    "    is.function(g) && isdebugged(g)\n",
    "}\n",
    "\n",
    "which_debugged <- function(objnames,ns=NULL) {\n",
    "    if (!length(objnames)) return(character(0))\n",
    "    objnames[sapply(objnames,isdebugged_safe,ns=ns)]\n",
    "}\n",
    "\n",
    "all_debugged <- function(where=search(), show_empty=FALSE) {\n",
    "    ss <- setNames(lapply(where,function(x) {\n",
    "        which_debugged(ls(x,all.names=TRUE))\n",
    "        }),gsub(\"package:\",\"\",where))\n",
    "    ## find attached namespaces\n",
    "    ## (is there a better way to test whether a \n",
    "    ##    namespace exists with a given name??)\n",
    "    ns <- unlist(sapply(gsub(\"package:\",\"\",where),\n",
    "                 function(x) {\n",
    "                     if (inherits({n <- try(getNamespace(x),silent=TRUE)},\n",
    "                         \"try-error\")) NULL else x\n",
    "                 }))\n",
    "    ss_ns <- setNames(lapply(ns,function(x) {\n",
    "        objects <- ls(getNamespace(x),all.names=TRUE)\n",
    "        which_debugged(objects,ns=x)\n",
    "        }),ns)\n",
    "    if (!show_empty) {\n",
    "        ss <- ss[sapply(ss,length)>0]\n",
    "        ss_ns <- ss_ns[sapply(ss_ns,length)>0]\n",
    "    }\n",
    "    ## drop overlaps\n",
    "    for (i in names(ss))\n",
    "        ss_ns[[i]] <- setdiff(ss_ns[[i]],ss[[i]])\n",
    "    list(env=ss,ns=ss_ns)\n",
    "}\n",
    "\n",
    "undebug_all <- function(where=search()) {\n",
    "    aa <- all_debugged(where)\n",
    "    lapply(aa$env,undebug)\n",
    "    ## now debug namespaces\n",
    "    invisible(mapply(function(ns,fun) {\n",
    "        undebug(getFromNamespace(fun,ns))\n",
    "    },names(aa$ns),aa$ns))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### CHANGE IN utilities.R in broom package\n",
    "#######################################\n",
    "#######################################\n",
    "# # this version adds a terms column\n",
    "# broom_confint_terms <- function(x, ...) {\n",
    "#   # print('BROOM CONFINT TERMS <<')\n",
    "#   # warn on arguments silently being ignored\n",
    "#   rlang::check_dots_used()\n",
    "#   ci <- tryCatch({\n",
    "#     confint(x, ...)\n",
    "#   }, error = function(e) {\n",
    "#     cat(\"Error in confint: \", e$message, \"\\n\")\n",
    "#     NULL\n",
    "#   })\n",
    "#   # ci <- suppressMessages(confint(x, ...))\n",
    "\n",
    "#   # confint called on models with a single predictor\n",
    "#   # often returns a named vector rather than a matrix :(\n",
    "\n",
    "#   if (is.null(ci)){\n",
    "#     ci <- confint.default(x)\n",
    "#   }\n",
    "\n",
    "#   if (is.null(dim(ci))) {\n",
    "#     ci <- matrix(ci, nrow = 1)\n",
    "#     print(paste0('ci:>>',ci))\n",
    "#     rownames(ci) <- names(coef(x))[1]\n",
    "#   }\n",
    "\n",
    "#   ci <- as_tibble(ci, rownames = \"term\", .name_repair = \"minimal\")\n",
    "#   names(ci) <- c(\"term\", \"conf.low\", \"conf.high\")\n",
    "#   ci\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check if the specified Python path exists\n",
    "check_python_path <- function(python_path) {\n",
    "  if (file.exists(python_path)) {\n",
    "    Sys.setenv(RETICULATE_PYTHON = python_path)\n",
    "    return(TRUE)\n",
    "  } else {\n",
    "    return(FALSE)\n",
    "  }\n",
    "}\n",
    "# check_python_path(\"/usr/local/bin/python3\")\n",
    "# check_python_path(\"/Users/fareedsuri/miniforge3/bin/python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Install a Python package using reticulate\n",
    "# install_python_package <- function(package_name) {\n",
    "#   reticulate::py_install(package_name)\n",
    "# }\n",
    "\n",
    "# Example usage: Install the openpyxl package\n",
    "# install_python_package(\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to find the Python path\n",
    "find_python_path <- function() {\n",
    "  python_path <- Sys.which(\"python3\")\n",
    "  if (python_path == \"\") {\n",
    "    stop(\"Python executable not found in the system PATH.\")\n",
    "  }\n",
    "  return(python_path)\n",
    "}\n",
    "\n",
    "# Set the RETICULATE_PYTHON environment variable\n",
    "# python_path <- find_python_path()\n",
    "# Sys.setenv(RETICULATE_PYTHON = python_path)\n",
    "\n",
    "# Print the Python path to verify\n",
    "# print(paste(\"Using Python at:\", python_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "as_flextable <- flextable::as_flextable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# shf <- read.csv('CREST_Analysis/recodeformulashortcuts.csv') # short functions\n",
    "# shf_1 <- shf[shf['type']==1,]\n",
    "# shf_2 <- shf[shf['type']==2,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# shf[shf['type']==1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "report_file <- function(){return(format(Sys.time(), \"%Y%m%d_%H%M%S\"))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'20240413_205344.R'</li><li>'Analysis'</li><li>'Analysis - Copy'</li><li>'CAS_International_LTF_20230801.csv'</li><li>'CAS_International_LTF_20230801.xlsx'</li><li>'CAS_International_PROC_20230801.csv'</li><li>'CAS_International_PROC_20230801.xlsx'</li><li>'CAS_NEW_LTF_data_dictionary_20230801.xlsx'</li><li>'CAS_NEW_LTF_data_dictionary_20230801_FS01a.xlsx'</li><li>'CAS_NEW_PROC_data_dictionary_20230801.xlsx'</li><li>'CAS_NEW_PROC_data_dictionary_20230801_FS01a.xlsx'</li><li>'Death and Survival Days Logic.pdf'</li><li>'Timing-CAS-V2.docx'</li><li>'Variable-of-interest.docx'</li><li>'dummy.docx'</li><li>'test.svg'</li><li>'voi.csv'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '20240413\\_205344.R'\n",
       "\\item 'Analysis'\n",
       "\\item 'Analysis - Copy'\n",
       "\\item 'CAS\\_International\\_LTF\\_20230801.csv'\n",
       "\\item 'CAS\\_International\\_LTF\\_20230801.xlsx'\n",
       "\\item 'CAS\\_International\\_PROC\\_20230801.csv'\n",
       "\\item 'CAS\\_International\\_PROC\\_20230801.xlsx'\n",
       "\\item 'CAS\\_NEW\\_LTF\\_data\\_dictionary\\_20230801.xlsx'\n",
       "\\item 'CAS\\_NEW\\_LTF\\_data\\_dictionary\\_20230801\\_FS01a.xlsx'\n",
       "\\item 'CAS\\_NEW\\_PROC\\_data\\_dictionary\\_20230801.xlsx'\n",
       "\\item 'CAS\\_NEW\\_PROC\\_data\\_dictionary\\_20230801\\_FS01a.xlsx'\n",
       "\\item 'Death and Survival Days Logic.pdf'\n",
       "\\item 'Timing-CAS-V2.docx'\n",
       "\\item 'Variable-of-interest.docx'\n",
       "\\item 'dummy.docx'\n",
       "\\item 'test.svg'\n",
       "\\item 'voi.csv'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '20240413_205344.R'\n",
       "2. 'Analysis'\n",
       "3. 'Analysis - Copy'\n",
       "4. 'CAS_International_LTF_20230801.csv'\n",
       "5. 'CAS_International_LTF_20230801.xlsx'\n",
       "6. 'CAS_International_PROC_20230801.csv'\n",
       "7. 'CAS_International_PROC_20230801.xlsx'\n",
       "8. 'CAS_NEW_LTF_data_dictionary_20230801.xlsx'\n",
       "9. 'CAS_NEW_LTF_data_dictionary_20230801_FS01a.xlsx'\n",
       "10. 'CAS_NEW_PROC_data_dictionary_20230801.xlsx'\n",
       "11. 'CAS_NEW_PROC_data_dictionary_20230801_FS01a.xlsx'\n",
       "12. 'Death and Survival Days Logic.pdf'\n",
       "13. 'Timing-CAS-V2.docx'\n",
       "14. 'Variable-of-interest.docx'\n",
       "15. 'dummy.docx'\n",
       "16. 'test.svg'\n",
       "17. 'voi.csv'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"20240413_205344.R\"                               \n",
       " [2] \"Analysis\"                                        \n",
       " [3] \"Analysis - Copy\"                                 \n",
       " [4] \"CAS_International_LTF_20230801.csv\"              \n",
       " [5] \"CAS_International_LTF_20230801.xlsx\"             \n",
       " [6] \"CAS_International_PROC_20230801.csv\"             \n",
       " [7] \"CAS_International_PROC_20230801.xlsx\"            \n",
       " [8] \"CAS_NEW_LTF_data_dictionary_20230801.xlsx\"       \n",
       " [9] \"CAS_NEW_LTF_data_dictionary_20230801_FS01a.xlsx\" \n",
       "[10] \"CAS_NEW_PROC_data_dictionary_20230801.xlsx\"      \n",
       "[11] \"CAS_NEW_PROC_data_dictionary_20230801_FS01a.xlsx\"\n",
       "[12] \"Death and Survival Days Logic.pdf\"               \n",
       "[13] \"Timing-CAS-V2.docx\"                              \n",
       "[14] \"Variable-of-interest.docx\"                       \n",
       "[15] \"dummy.docx\"                                      \n",
       "[16] \"test.svg\"                                        \n",
       "[17] \"voi.csv\"                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list.files(path = getwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'crest_analysis/20240604_232449.R'"
      ],
      "text/latex": [
       "'crest\\_analysis/20240604\\_232449.R'"
      ],
      "text/markdown": [
       "'crest_analysis/20240604_232449.R'"
      ],
      "text/plain": [
       "[1] \"crest_analysis/20240604_232449.R\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xfun::with_ext(paste0('crest_analysis/',report_file()), \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# library(rmarkdown)\n",
    "# library(knitr)\n",
    "# library(xfun)\n",
    "convert_ipynb_to_r <- function(\n",
    "    input, \n",
    "    output = xfun::with_ext(paste0('crest_analysis/',report_file()), \"R\"),\n",
    "    keep_rmd = FALSE,\n",
    "    ...\n",
    ") {\n",
    "    ## Check if necessary packages are installed\n",
    "    if (!require(\"rmarkdown\")) return(\"Missing necessary package: 'rmarkdown'\")\n",
    "    if (!require(\"knitr\")) return(\"Missing necessary package: 'knitr'\")\n",
    "\n",
    "    ## Check if file extension is matches Jupyter notebook.\n",
    "    if (tolower(xfun::file_ext(input)) != \"ipynb\") { \n",
    "        return( \"Error: Invalid file format\" )\n",
    "    }\n",
    "\n",
    "    ## Conversion process: \n",
    "    ## .ipynb to .Rmd\n",
    "    rmarkdown::convert_ipynb(input)\n",
    "    ## .Rmd to .R\n",
    "    knitr::purl(xfun::with_ext(input, \"Rmd\"), output = output)\n",
    "\n",
    "    ## Keep or remove intermediary .Rmd\n",
    "    if (keep_rmd == FALSE) {\n",
    "        file.remove(xfun::with_ext(input, \"Rmd\"))\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "histogram_theme <- theme(\n",
    "    plot.title = element_text(size = 8),# title\n",
    "    axis.text = element_text(size = 4) ,# ticks\n",
    "    axis.title = element_text(size = 6), # title of axis\n",
    "    panel.background = element_rect(fill = \"white\"),\n",
    "    axis.line = element_line(color = \"black\"),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "histogram_bin_label <- geom_text(\n",
    "  stat = \"count\",\n",
    "  aes(label =  after_stat(count)),\n",
    "  vjust = -0.05,\n",
    "  color = \"black\",\n",
    "  size = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/latex": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/markdown": [
       "'/Users/fareedsuri/SynologyDrive/Data/CarotidData2023'"
      ],
      "text/plain": [
       "[1] \"/Users/fareedsuri/SynologyDrive/Data/CarotidData2023\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# data_loaded <- read_csv( 'CAS_International_PROC_20230801.csv')\n",
    "# data_ltf <- read_csv( 'CAS_International_LTF_20230801.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# original<- read_excel('Analysis/recode.xlsx',sheet = \"original\") \n",
    "# recode <- read_excel('Analysis/recode.xlsx',sheet = \"recode\")\n",
    "# analysis <- read_excel('Analysis/recode.xlsx',sheet = \"analysis\")\n",
    "# recode <- dplyr::bind_rows(original,recode)\n",
    "# recode <- filter(recode,!is.na(nvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# names(recode)[duplicated(names(recode))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### rename columns from recode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### calculated columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### automated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# load_file <- function(file_name) {\n",
    "#   print(file_name)\n",
    "#   data_loaded <- read_csv(file_name)\n",
    "#   print(paste('loaded:',file_name, ',n=',nrow(data_loaded)))\n",
    "#   return(data_loaded)\n",
    "# }\n",
    "\n",
    "load_file <- function(file_name) {\n",
    "  # print(file_name)\n",
    "  # Determine the file extension\n",
    "  file_ext <- tools::file_ext(file_name)\n",
    "  \n",
    "  if (file_ext == \"csv\") {\n",
    "    data_loaded <- read_csv(file_name)\n",
    "  } else if (file_ext == \"sas7bdat\") {\n",
    "    # Assuming you have the haven package installed and loaded\n",
    "    data_loaded <- haven::read_sas(file_name)\n",
    "  } else {\n",
    "    stop(\"Unsupported file type\")\n",
    "  }\n",
    "  \n",
    "  # print(paste('loaded:', file_name, ', n=', nrow(data_loaded)))\n",
    "  return(data_loaded)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ept <- function(t){\n",
    "  return(eval(parse(text=t)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "comma_sep_list <- function(x){\n",
    "  paste(names(x), \"=\", sapply(x, toString), collapse = \", \")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fix_forumla <- function(fx,patterns,quote_var= FALSE) {\n",
    "  # print(patterns)\n",
    "  df_name<-deparse(substitute(df))\n",
    "  # fx<-row[['fx']]\n",
    "  # var_name<-row[['nvar']]\n",
    "  \n",
    "  # first replace #df with df value\n",
    "  # print(fx)\n",
    "  # print(df_name)\n",
    "  fx <- str_replace_all(fx,\"\\\\$df\",df_name)\n",
    "  if(is.na(fx)){\n",
    "    return(NA)\n",
    "  }\n",
    "\n",
    "  # parenthesis functions\n",
    "  matches <- str_match_all(fx, patterns[1])\n",
    "  m <- matches[[1]] # first element in match list \n",
    "  if (length(m) > 0) {\n",
    "    for (i in 1:nrow(m)){\n",
    "      mm<- str_match( m[i,],'^(.*?)([\\\\$\\\\#].*)')\n",
    "      f <- shf_2[shf_2['var']==mm[[2]],'nvar']\n",
    "      v <- mm[[3]]\n",
    "      r <- paste(f,'(',v,')')  \n",
    "      r<-gsub(\" \",\"\",r)\n",
    "      r<-paste(' ',r)\n",
    "      p <- str_c(\"\\\\b\", mm[[2]], \"\\\\\",mm[[3]],\"\\\\b\")\n",
    "      fx <- str_replace_all(fx,p,r)\n",
    "    }\n",
    "  } \n",
    "  # print(paste('1:',fx))\n",
    "  \n",
    "  # switch\n",
    "  sw <- str_match(fx,'^switch\\\\((.*)\\\\)')[[2]]\n",
    "  tryCatch({  \n",
    "    if (!is.na(sw)) {\n",
    "      m<-regexec('var:(.*?),(.*),else:(.*)',sw) # position of var, cond(s) and else\n",
    "      if (length(m[[1]]) & m[[1]][1]>0){ \n",
    "        l<-regmatches(sw,m)[[1]] # value of var, cond(s) and else    \n",
    "        else_val<-l[[4]]\n",
    "        var_<-l[[2]]\n",
    "        conds<-str_split(l[[3]],',')[[1]]\n",
    "        built<-''\n",
    "        for (e in length(conds):1){\n",
    "          splits<-str_split(conds[[e]],':')[[1]]\n",
    "          cond<-splits[[1]]\n",
    "          val<-splits[[2]]\n",
    "          built<-paste0('ifelse(',var_,cond,',',val,',',built)\n",
    "        }\n",
    "        built<-paste0(built,else_val)\n",
    "        for (e in length(conds):1){\n",
    "          built <- paste0(built,')')\n",
    "        }\n",
    "        fx<-built # rebuilt formula\n",
    "      } else {\n",
    "        m<-regexec('(.*?:.*?),else:(.*)',sw)\n",
    "        l<-regmatches(sw,m)[[1]]\n",
    "        else_val<-l[[3]]\n",
    "        conds<-str_split(l[[2]],',')[[1]]\n",
    "        built<-''\n",
    "        for (e in length(conds):1){\n",
    "          splits<-str_split(conds[[e]],':')[[1]]\n",
    "          cond<-splits[[1]]\n",
    "          val<-splits[[2]]\n",
    "          built<-paste0('ifelse(',cond,',',val,',',built)\n",
    "        }\n",
    "        built<-paste0(built,else_val)\n",
    "        for (e in length(conds):1){\n",
    "          built <- paste0(built,')')\n",
    "        }\n",
    "        fx<-built # rebuilt formula\n",
    "      }\n",
    "    } \n",
    "  },\n",
    "  error=function(e){\n",
    "    print(paste('error in switch',e))\n",
    "  })\n",
    "  # print(paste('2:',fx))\n",
    "  \n",
    "  \n",
    "  # variables \n",
    "  matches <- str_match_all(fx, patterns[2])\n",
    "  m <- matches[[1]] \n",
    "  if (length(m) > 0) {\n",
    "    for (i in 1:nrow(m)){\n",
    "      sign <- substr(m[i,],1,1)\n",
    "      v <-substring( m[i,],2)\n",
    "      # is_only_digits <- grepl(\"^\\\\d+$\", v)\n",
    "      # if(is_only_digits){\n",
    "        # r1<-paste(recode[recode['id']==v,'nvar'])\n",
    "      # } else {\n",
    "        r1<-v\n",
    "      # }\n",
    "      r2<- ifelse(quote_var == TRUE, paste('\"',r1,'\"'),r1)\n",
    "      r3 <- ifelse(sign == \"#\", paste(df_name, \"$\", r2), r2)\n",
    "      r4<-gsub(\" \",\"\",r3)\n",
    "      r<-paste(' ',r4)\n",
    "      p <- str_c(\"\\\\\",sign,v,\"\\\\b\")\n",
    "      fx <- str_replace_all(fx,p,r)      \n",
    "    } \n",
    "  } \n",
    "  # print(paste('3:',fx,'  v:',v,'  r1:',r1,'  r2:',r2,'  r3:',r3,'  r4:',r4,'  r:',r,'  p:',p))\n",
    "  \n",
    "  # non-parenthesis functions\n",
    "  matches <- str_match_all(fx, patterns[3])\n",
    "  m <- matches[[1]] \n",
    "  if (length(m) > 0) {\n",
    "    for (i in 1:nrow(m)){\n",
    "      v <- m[i,]\n",
    "      r <- shf_1[shf_1['var']==v,'nvar']\n",
    "      p <- str_c(\"\\\\b\",v,\"\\\\b\")\n",
    "      fx <- str_replace_all(fx,p,r)\n",
    "    }\n",
    "  } \n",
    "  # print(paste('3:',fx))\n",
    "  # if (return_fx ) {return(fx)}\n",
    "  return(fx)\n",
    "# tryCatch({\n",
    "#   tib <- tibble::tibble(!!var_name := eval(parse(text=fx))) # DONT CHANGE TO ept(fx)\n",
    "#   df <- cbind(df,tib)\n",
    "#   print(paste('CREATED:',var_name,' with forumla ', fx))\n",
    "# }, error = function(e){\n",
    "#   print(paste('ERR:',var_name,' with forumla ', fx,' ERROR: ',e))\n",
    "#   stop()\n",
    "# }, finally = {\n",
    "#   return(list(df=df,fx=fx))\n",
    "# })\n",
    "}\n",
    "\n",
    "add_forumla_variable <- function(fx,var_name,df){\n",
    "  # print(paste(var_name,':',fx))\n",
    "  tryCatch({\n",
    "    if (startsWith(fx,\"minVar(\")){\n",
    "      fx<-fix_forumla('min_var(c($var1,$var2,$var3))',patterns,quote_var= TRUE)\n",
    "    } else {\n",
    "    \n",
    "      suppressWarnings(tib <- tibble::tibble(!!var_name := eval(parse(text=fx)))) # DONT CHANGE TO ept(fx)\n",
    "      suppressWarnings(df <- cbind(df,tib))\n",
    "      print(paste('CREATED:',var_name,' with forumla ', fx))\n",
    "    }\n",
    "  }, error = function(e){\n",
    "    print(paste('ERR:',var_name,' with forumla ', fx,' ERROR: ',e))\n",
    "    stop()\n",
    "  }, finally = {\n",
    "    return(df)\n",
    "  })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ctn1_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "    processed_args<-get_args(recode,analysis_row,1,1,patterns)\n",
    "    doc <- add__n(analysis_row[['in']],doc)\n",
    "    ft<- ctn1(analysis_row[['in']],processed_args)\n",
    "    ft<- labelit(ft, recode, processed_args[[1]])\n",
    "    if(disp_){disp(to_html(ft))}\n",
    "    doc <- add_text_(doc, get_title(analysis_row))\n",
    "    doc <- body_add_flextable(doc, ft)\n",
    "    doc <- body_add_break(doc)\n",
    "    return(doc)\n",
    "}\n",
    "ctn1 <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  cols<-args[[1]]\n",
    "  arg<-args[[2]]\n",
    "\n",
    "  ct <-  crosstable(\n",
    "    df,\n",
    "    cols =all_of(cols),\n",
    "    percent_pattern =arg,\n",
    "    percent_digits = 0\n",
    "    \n",
    "    )\n",
    "    print(ct)\n",
    "    ft<- ct |> \n",
    "    crosstable::as_flextable(spread_first_col = TRUE,separate_with = \"label\") |>\n",
    "    # theme_tron() |> \n",
    "    fix_border_issues() |>\n",
    "    autofit() |>\n",
    "    set_caption(caption=\"Automated analysis\")\n",
    "    # print(ct)\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ctn3_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "        processed_args<-get_args(recode,analysis_row,1,1,patterns)\n",
    "      doc <- add__n(analysis_row[['in']],doc)\n",
    "      ft<- (ctn3(analysis_row[['in']],processed_args))$ft\n",
    "      if(disp_){disp(to_html(ft))}\n",
    "      doc <- add_text_(doc, get_title(analysis_row))\n",
    "      doc <- body_add_flextable(doc, ft)\n",
    "      doc <- body_add_break(doc)\n",
    "}\n",
    "# CTN3  1 set of variables for crosstabling\n",
    "ctn3 <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  vars <- args[[1]]\n",
    "  stat <- args[[2]]\n",
    "  var_levels <- list()\n",
    "  var_level_labels <- list()\n",
    "  var_count <- 0\n",
    "  \n",
    "  ctn <- function(df,col,cols,stat){\n",
    "    ct <-  crosstable(\n",
    "      df,\n",
    "      cols =all_of(cols),\n",
    "      by = all_of(col),\n",
    "      percent_pattern =stat,\n",
    "      percent_digits = 0\n",
    "      ) \n",
    "      var_count <<- var_count +1 \n",
    "      var_level_labels[[var_count]] <<- names(ct)\n",
    "      \n",
    "      l <<- length(names(ct))\n",
    "      var_levels <<- c(var_levels, l-3)\n",
    "      # print(vars(4:l))\n",
    "    \n",
    "      ct <- ct |>\n",
    "        rename_at(vars(4:l), ~ paste0(col,\"@\", .))\n",
    "      return(ct)\n",
    "  }\n",
    "  \n",
    "  # first\n",
    "  tib <- ctn(df,vars[1],vars[-1],stat) \n",
    "  if (length(vars) == 2) {\n",
    "    return(tib)\n",
    "  }\n",
    "  \n",
    "  # others\n",
    "  for (i in seq_along(vars)[-1]) {\n",
    "    vars_other <- vars[-i]\n",
    "      ct <- ctn(df,vars[i],vars_other,stat)\n",
    "      tib <- tib |> full_join (ct)\n",
    "  }\n",
    "  \n",
    "  # replace NA with \".\"\n",
    "  tib <- tib |> mutate_all(~ replace(.,  is.na(.), \".\"))\n",
    "  \n",
    "  # flextable start\n",
    "  ft<-as_flextable(tib)\n",
    "  ft<-ft|> delete_rows(i=1:2,part='header')\n",
    "  \n",
    "  # header row 2\n",
    "  header_row_labels <- c(\"label\",\"variable\")\n",
    "  col_widths <- c(1,1)\n",
    "  for (i in seq_along(var_level_labels)) {\n",
    "    var_level_label <- var_level_labels[[i]]\n",
    "    n<- length(var_level_label)\n",
    "    for (j in seq_along(var_level_label)[4:n]) {\n",
    "      header_row_labels <- append(header_row_labels,var_level_label[j])\n",
    "      col_widths <- append(col_widths,1)\n",
    "    }\n",
    "  }\n",
    "  ft <- ft |> add_header_row(\n",
    "      values = header_row_labels,\n",
    "      colwidths = col_widths\n",
    "    )\n",
    "    \n",
    "  # header row 1\n",
    "  \n",
    "  header_row_labels <- c(\"\",\"\")\n",
    "  col_widths <- c(1,1)\n",
    "  for (i in seq_along(vars)){\n",
    "    header_row_labels <- append(header_row_labels,vars[i])\n",
    "    col_widths <- append(col_widths,var_levels[[i]])\n",
    "  }\n",
    "  ft <- ft |> add_header_row(\n",
    "      values = header_row_labels,\n",
    "      colwidths = col_widths\n",
    "    )\n",
    "  ft <- ft |> \n",
    "  align(\n",
    "    align = \"center\",\n",
    "    part = \"header\"\n",
    "  )  |>\n",
    "  bold(\n",
    "    bold = TRUE,\n",
    "    part = \"header\"\n",
    "  ) |>\n",
    "  bold(\n",
    "    j= 1:2,\n",
    "    part = \"body\"\n",
    "  )|> \n",
    "  align(\n",
    "    align = \"right\",\n",
    "    part = \"body\"\n",
    "  )\n",
    "\n",
    "  return(list(ft=ft,tib=tib))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "refilter <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  arg <- args[[1]]\n",
    "  df <- df |> filter(eval(parse(text = arg)))\n",
    "  print(paste('filtered:',args,', n=',nrow(df)))\n",
    "  return (df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "get_title <- function(analysis_row) {\n",
    "  title <- analysis_row[['title']]\n",
    "  if (is.null(title)) {\n",
    "    if (!is.null(analysis_row[['1']])) {\n",
    "      title <- analysis_row[['1']]\n",
    "    } else {\n",
    "      title <- \"\"\n",
    "    }\n",
    "  }\n",
    "  return(title)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "subset <- function(df_name,args){\n",
    "  # print('SUBSET')\n",
    "  df<-get(df_name)\n",
    "  not_in_df <- args[!args %in% names(df)]\n",
    "  if (length(not_in_df) > 0) {\n",
    "    print(paste('subset:',not_in_df))\n",
    "    stop(paste('NOT IN DF'))\n",
    "  }\n",
    "  # arg <- args[[1]]\n",
    "  # print(args)\n",
    "  # print(names(df[args]))\n",
    "  df <- df[args]\n",
    "  return (df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summ_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "        processed_args<-get_args(analysis_row,2,1,patterns)\n",
    "      doc <- body_add_break(doc)\n",
    "      doc <- add__n(analysis_row[['in']],doc)\n",
    "      ft<- summ(analysis_row[['in']],processed_args[[2]])\n",
    "      if (disp_) {disp(to_html(ft))}\n",
    "      doc <- add_text_(doc, get_title(analysis_row))\n",
    "      doc <- body_add_flextable(doc, ft)\n",
    "}\n",
    "summ <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  col<-args[[1]]\n",
    "  cols<-args[[2]]\n",
    "  filt = args[[3]]\n",
    "  ft <- df |> \n",
    "  select(all_of(cols)) |>\n",
    "  filter(eval(parse(text=filt)))|>\n",
    "  summarizor(\n",
    "    by =col,\n",
    "    ) |> \n",
    "    as_flextable(\n",
    "      sep_w =0, \n",
    "      spread_first_col = TRUE,\n",
    "      columns_alignment ='right',\n",
    "    ) |>\n",
    "    theme_tron() |> \n",
    "    fix_border_issues() |>\n",
    "    autofit() |>\n",
    "    set_caption(caption=col) |>\n",
    "    italic(j=1,part=\"body\")\n",
    "    # print(ft)\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "parse_json <- function(text){\n",
    "  # 'a:1,b:2' will return $a<-'1',$b<-'2'\n",
    "  pattern_json <- \"([^\\\\{\\\\s:,]+)\"\n",
    "  json_string<- paste0(\"{\",gsub(pattern_json, \"\\\"\\\\1\\\"\", text, perl = TRUE),\"}\")\n",
    "  parsed_data <- fromJSON(json_string)\n",
    "  return(parsed_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "freq1_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "  processed_args<-get_args(analysis_row,1,0,patterns)\n",
    "  doc <- body_add_break(doc)\n",
    "  doc <- add__n(analysis_row[['in']],doc)\n",
    "  # print(paste('freq1_shell::df_name:>>',analysis_row[['in']]))\n",
    "\n",
    "  var <- processed_args[[1]]\n",
    "\n",
    "  ft<- freq1(analysis_row[['in']],var)\n",
    "  if (disp_) {disp(to_html(ft))}\n",
    "  if (!is.na(get_title(analysis_row))){\n",
    "    doc <- add_text_(doc, get_title(analysis_row))\n",
    "  } else {\n",
    "    # print(paste('freq1_shell::df_name:>>',find_label(processed_args[[1]])))\n",
    "    doc <- add_text(doc,find_label(processed_args[[1]]) )\n",
    "  }\n",
    "  doc <- body_add_flextable(doc, ft)\n",
    "}\n",
    "freq1 <- function(df_name,var){\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  ft <- proc_freq(df,var) |>\n",
    "    theme_tron() |> \n",
    "    fix_border_issues() |>\n",
    "    autofit() |>\n",
    "    set_caption(caption=var)\n",
    "  print(ft)\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "freq2_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "        processed_args<-get_args(analysis_row,2,0,patterns)\n",
    "      doc <- body_add_break(doc)\n",
    "      doc <- add__n(analysis_row[['in']],doc)\n",
    "      ft<- freq2(analysis_row[['in']],processed_args)\n",
    "      if (disp_) {disp(to_html(ft))}\n",
    "      doc <- add_text_(doc, get_title(analysis_row))\n",
    "      doc <- body_add_flextable(doc, ft)\n",
    "}\n",
    "freq2 <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  col <- args[[1]]\n",
    "  row <- args[[2]]\n",
    "  ft <- proc_freq(df,row,col) |>\n",
    "      theme_tron() |> \n",
    "    fix_border_issues() |>\n",
    "    autofit() |>\n",
    "    set_caption(caption=col)\n",
    "    print(ft)\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "freq_list_shell <- function(recode,analysis_row,patterns,doc){\n",
    "  processed_args<-get_args(analysis_row,1,0,patterns)\n",
    "  doc <- body_add_break(doc)\n",
    "  doc <- add__n(analysis_row[['in']],doc)\n",
    "  vars<-processed_args[[1]]\n",
    "  \n",
    "  if (!is.na(get_title(analysis_row))){\n",
    "    doc <- add_text_(doc, get_title(analysis_row))\n",
    "  } else {\n",
    "    doc <- add_text(doc,find_label(vars) )\n",
    "  }\n",
    "  df_name<-analysis_row[['in']]\n",
    "  doc<- freq_list(df_name,vars,doc)\n",
    "  # if (disp_) {disp(to_html(ft))}\n",
    "\n",
    "  # doc <- body_add_flextable(doc, ft)\n",
    "}\n",
    "freq_list <- function(df_name,vars,doc){\n",
    "  print(vars)\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  # vars <- args[[1]]\n",
    "  for (v in 1:length(vars)){\n",
    "    ft <- proc_freq(df,vars[v]) |>\n",
    "      theme_tron() |> \n",
    "      fix_border_issues() |>\n",
    "      autofit() |>\n",
    "      set_caption(caption=v)\n",
    "    label <- recode[recode$nvar==vars[v],][['label']]\n",
    "    # print(label)\n",
    "    if (!is.na(label)) {\n",
    "      names(ft$body$dataset)[1]<-label\n",
    "    }\n",
    "    if (disp_) {disp(to_html(ft))}\n",
    "    doc <- body_add_flextable(doc, ft)  \n",
    "  }\n",
    "  \n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add__n <- function(df_name,doc,t=\"\"){\n",
    "  df<-get(df_name)\n",
    "  doc <- doc %>%\n",
    "    body_add_par(paste(t), pos = \"after\",style=\"Normal\") |>\n",
    "    body_add_par(paste(\"n=\",nrow(df)),style=\"Normal\", pos = \"after\") |>\n",
    "    body_add_par(\"\", pos = \"after\",style=\"Normal\")\n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_text_ <- function(doc,text) {\n",
    "  # print('adding')\n",
    "  if (!is.na(text)) {\n",
    "    add_text(doc, get_title(analysis_row))\n",
    "  }\n",
    "  # print('added')\n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "add_text <- function(doc,t,level=2,type=\"normal\"){\n",
    "  # print(paste0('ADD TEXT>>',t))\n",
    "  if (type==\"normal\"){  color=\"black\"}\n",
    "  if (type==\"critical\"){  color=\"#612008\"}\n",
    "  if (type==\"note\"){  color=\"#4a4d64\"}\n",
    "  if (level==1){\n",
    "    text_style <- fp_text(font.size = 20,color=color,bold=TRUE)    \n",
    "    par_style <- fp_par(text.align = \"left\")\n",
    "  \n",
    "  } else if (level==2){\n",
    "    text_style <- fp_text(font.size = 14,color=color,bold=TRUE)   \n",
    "    par_style <- fp_par(text.align = \"left\")\n",
    "  \n",
    "  } else if (level==3){\n",
    "    text_style <- fp_text(font.size = 12,color=color,underlined=TRUE)      \n",
    "    par_style <- fp_par(text.align = \"left\")\n",
    "  \n",
    "  } else if  (level==8){ # paragraph\n",
    "    text_style <- fp_text(font.size = 12,color=color,bold=FALSE)\n",
    "    par_style <- fp_par(text.align = \"left\")\n",
    "  } else if  (level>8){ # paragraph\n",
    "    text_style <- fp_text(font.size = 9,color=color,bold=FALSE)\n",
    "    par_style <- fp_par(text.align = \"left\")\n",
    "  }\n",
    "\n",
    "  doc <- body_add_fpar(doc, fpar( ftext(t, prop = text_style), fp_p = par_style ) )\n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_count <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  var <- gsub(\" \", \"\", processed_args[[1]])\n",
    "  tib <- as_tibble(table(df[[var]]),.name_repair = \"minimal\")\n",
    "  names(tib)[1]<-var\n",
    "  return(tib)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot_hist_l <- function(df_name,args,doc,titles){\n",
    "  variable_names <- ept(args[[1]])\n",
    "  print(variable_names)\n",
    "  titles <-  strsplit(titles, split = \"|\", fixed = TRUE)[[1]]\n",
    "  for (i in seq_along(variable_names)) {\n",
    "    var <- variable_names[[i]]  # Get the variable name\n",
    "    title <- titles[i]          # Get the corresponding title\n",
    "    var_name<-deparse(substitute(var))\n",
    "    print(var_name)\n",
    "    plot<-ggplot_hist(df_name,c(var_name))\n",
    "    doc <- doc |> body_add_break() |> add_text( title) |>body_add_gg(plot, width = 6, height = 4)\n",
    "  }\n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot_hist <- function(df_name,args){\n",
    "  # df<-get(args[[2]])\n",
    "  df<-get(df_name)\n",
    "  x_var <-ept(args[[1]])\n",
    "  print(x_var)\n",
    "  print(  names(df))\n",
    "  histogram <- ggplot(df, aes(x = .data[[x_var]])) +\n",
    "  geom_histogram(binwidth = 0.5, fill = \"grey\", color = \"black\", alpha = 0.5) +  # Customize the histogram aesthetics\n",
    "  labs(x = \"Values\", y = \"Frequency\", title = \"Histogram of Values\") +  # Add labels and title\n",
    "  stat_bin(geom = \"text\", aes(label = ifelse(..count.. > 0, ..count.., \"\")), vjust = -0.5) +  # Add count labels on top of each bar\n",
    "  theme_minimal()  # Apply a theme (optional)\n",
    "  return(histogram)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set_widths <- function(ft,col1=2,other_cols=0.75){\n",
    "  ft<-width(ft,j=1,width=col1)\n",
    "  for(i in 2:ncol_keys(ft)){\n",
    "    ft<-width(ft,j=i,width=other_cols)\n",
    "  }\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot_bar <- function(df_name,args) {\n",
    "  # arg 3 = df name\n",
    "  # df<-get(args[[3]])\n",
    "  df<-get(df_name)\n",
    "  x_var <-ept(args[[2]])\n",
    "  y_var <- ept(args[[1]])\n",
    "  \n",
    "  bar_graph<-ggplot(df, aes(x = factor(.data[[x_var]]), y = .data[[y_var]])) + \n",
    "    geom_bar(stat = \"identity\", fill = \"grey\", width = 0.5) +\n",
    "    geom_text(aes(label = paste0(round(.data[[y_var]]*100,1),'%')), vjust = -0.5, color = \"black\", size = 3) +  \n",
    "    labs(x = \"evt_days\", y = \"Percentage\") +\n",
    "    ggtitle(\"Bar Plot of Percentages with Values\") +\n",
    "    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n",
    "    theme_minimal()\n",
    "    \n",
    "  return(bar_graph)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_props <- function(df_name,args) {\n",
    "    df<-get(df_name)\n",
    "    base_df <-get(args[[3]])\n",
    "    variable_names <- eval(parse(text=args[[1]]))\n",
    "    freq_var <- eval(parse(text=args[[2]]))\n",
    "    renamed_var <- args[[4]]\n",
    "    print(paste('renamed_var',renamed_var))\n",
    "    prop_dfs <- as_tibble(table(df[[freq_var]]),.name_repair = \"minimal\")\n",
    "    names(prop_dfs)[1]<-freq_var\n",
    "    is_factor <- is.factor(base_df[[freq_var]])\n",
    "    if (!is_factor) {\n",
    "      prop_dfs[[freq_var]]<- as.numeric(prop_dfs[[freq_var]])\n",
    "    }\n",
    "      \n",
    "    for (var_name in variable_names) {\n",
    "      prop_df <- aggregate(get(var_name) ~ get(freq_var), df, function(x) {\n",
    "        prop <- prop.table(table(x))\n",
    "        if (length(prop) == 1) {\n",
    "          prop <- c(prop, 0)  # If only one value, add proportion of the other value as 0\n",
    "        }\n",
    "        return(prop[2])\n",
    "      })\n",
    "      names(prop_df)[1]<-freq_var\n",
    "      names(prop_df)[2]<-var_name\n",
    "      prop_dfs <- merge(prop_dfs, prop_df, by = freq_var, all = TRUE,sort=FALSE)\n",
    "      \n",
    "    }\n",
    "    if (is_factor) {\n",
    "      prop_dfs[[freq_var]]<-factor(prop_dfs[[freq_var]],levels(df[[freq_var]]))\n",
    "    }\n",
    "  prop_dfs<- prop_dfs |> rename_with(~ renamed_var,1)  \n",
    "  return(prop_dfs)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "merge_props <- function(df_name,args,report_name) {\n",
    "  tb_list<-strsplit(args[[1]], split = '|', fixed = TRUE)[[1]]\n",
    "  outcome_names <- strsplit(args[[2]], split = '|', fixed = TRUE)[[1]]\n",
    "  df <- ept(tb_list[[1]]) |> mutate(tb=outcome_names[[1]])\n",
    "  for (i in 2:length(tb_list)) {\n",
    "    df<-bind_rows(df, ept(tb_list[[i]])|> mutate(tb=outcome_names[[i]]))\n",
    "  }\n",
    "  write.csv(df,paste0(report_name,'.csv'))\n",
    "  # print(names(df))\n",
    "  if('n' %in% colnames(df)) {\n",
    "    df<-select(df, -n)\n",
    "  }\n",
    "  return(df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot_bar_gp <- function(df_name,args) {\n",
    "  df<-get(df_name)\n",
    "  x_var <-ept(args[[2]])\n",
    "  y_var <- ept(args[[1]])\n",
    "  \n",
    " bar_graph<-ggplot(data = df_merge,\n",
    "       aes(x = .data[[x_var]], y = .data[[y_var]], group = factor(.data[['tb']]))\n",
    "    ) +\n",
    "    geom_bar(\n",
    "        stat = \"identity\",\n",
    "        aes(fill = factor(.data[['tb']])),\n",
    "        position = position_dodge(width = 0.9)\n",
    "    )\n",
    "  return(bar_graph)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ctn2_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "    processed_args<-get_args(analysis_row,2,1,patterns)\n",
    "    doc <- body_add_break(doc)\n",
    "    doc <- add__n(analysis_row[['in']],doc)\n",
    "    # print(paste('df_name:>>',analysis_row[['in']]))\n",
    "    ft<- ctn2(analysis_row[['in']],processed_args)\n",
    "    # ft<- labelit(ft, recode, processed_args[[2]])\n",
    "    if (disp_) {disp(to_html(ft))}\n",
    "      doc <- add_text_(doc, get_title(analysis_row))\n",
    "      doc <- body_add_flextable(doc, ft)\n",
    "}\n",
    "\n",
    "ctn2 <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  col<-args[[1]]\n",
    "  cols<-args[[2]]\n",
    "  arg<-args[[3]]\n",
    "  ct <-  crosstable(\n",
    "      data=df,\n",
    "      cols =all_of(cols),\n",
    "      by = all_of(col),\n",
    "      percent_pattern =arg,\n",
    "      percent_digits = 0,\n",
    "      funs=c(mean,sd)\n",
    "    )\n",
    "    # # add frequencies to headers\n",
    "    # frequencies <- table(df[[col]])\n",
    "    # names(ct)<-lapply(names(ct),function(x){\n",
    "    #   if(x %in% names(frequencies)){\n",
    "    #     returning <- paste0(x,' (N=',frequencies[[x]],')')\n",
    "    #     return (returning)\n",
    "    #   }  else {\n",
    "    #     return(x)\n",
    "    #   }\n",
    "    # })\n",
    "    \n",
    "    col_var <- recode[recode$nvar == col,'label'][[1]]\n",
    "\n",
    "    \n",
    "    print(tibble::tibble(ct))\n",
    "    ft<- ct |> \n",
    "    crosstable::as_flextable(spread_first_col = TRUE,separate_with = \"label\") |>\n",
    "    # theme_tron() |> \n",
    "    fix_border_issues() |>\n",
    "    autofit() |>\n",
    "    set_caption(caption=col) |>\n",
    "    labelizor(part=\"header\",\n",
    "        labels=c(\"label\"=\"variables\",\"variable\"=\"\",setNames(col_var,col)),\n",
    "        )\n",
    "    # print(ct)\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ctn4_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "  processed_args<-get_args(analysis_row,2,1,patterns)\n",
    "  doc <- add__n(analysis_row[['in']],doc)\n",
    "  ft<- (ctn4(analysis_row[['in']],processed_args))$ft\n",
    "  if(disp_){disp(to_html(ft))}\n",
    "  doc <- add_text_(doc, get_title(analysis_row))\n",
    "  doc <- body_add_flextable(doc, ft)\n",
    "  doc <- body_add_break(doc)\n",
    "}\n",
    "# CTN4 2 set of variables (cols and rows)\n",
    "ctn4 <- function(df_name,args){\n",
    "  df<-get(df_name)\n",
    "  \n",
    "  vars1 <- args[[1]] # columns\n",
    "  vars2 <- args[[2]] # rows\n",
    "  stat <- args[[3]]\n",
    "  var_levels <- list()\n",
    "  var_level_labels <- list()\n",
    "  var_count <- 0\n",
    "  ctn <- function(df,col,cols,stat){\n",
    "    ct <-  crosstable(\n",
    "      df,\n",
    "      cols =all_of(cols),\n",
    "      by = all_of(col),\n",
    "      percent_pattern =stat,\n",
    "      percent_digits = 0\n",
    "      ) \n",
    "      var_count <<- var_count +1 \n",
    "      var_level_labels[[var_count]] <<- names(ct)\n",
    "      \n",
    "      l <<- length(names(ct))\n",
    "      var_levels <<- c(var_levels, l-3)\n",
    "      ct <- ct |>\n",
    "        rename_at(vars(4:l), ~ paste0(col,\"@\", .))\n",
    "        \n",
    "      return(ct)\n",
    "  }\n",
    "\n",
    "  # first\n",
    "  tib <- ctn(df,vars1[1],vars2,stat) \n",
    "  # print(tib)\n",
    "  if (length(vars1) == 1) {\n",
    "    return(list(ft=as_flextable(tib),tib=tib))\n",
    "  }\n",
    "  \n",
    "  \n",
    "  # others\n",
    "  for (i in seq_along(vars1)[-1]) {\n",
    "    ct <- ctn(df,vars1[i],vars2,stat)\n",
    "    tib <- tib |> full_join (ct)\n",
    "  }\n",
    "  \n",
    "  # replace NA with \".\"\n",
    "  tib <- tib |> mutate_all(~ replace(.,  is.na(.), \".\"))\n",
    "  \n",
    "  # flextable start\n",
    "  ft<-as_flextable(tib)\n",
    "  \n",
    "  # delete header rows\n",
    "  ft<-ft|> delete_rows(i=1:2,part='header')\n",
    "  \n",
    "  # rebuild header row 2\n",
    "  header_row_labels <- c(\"label\",\"variable\")\n",
    "  col_widths <- c(1,1)\n",
    "  for (i in seq_along(var_level_labels)) {\n",
    "    var_level_label <- var_level_labels[[i]]\n",
    "    n<- length(var_level_label)\n",
    "    for (j in seq_along(var_level_label)[4:n]) {\n",
    "      header_row_labels <- append(header_row_labels,var_level_label[j])\n",
    "      col_widths <- append(col_widths,1)\n",
    "    }\n",
    "  }\n",
    "  ft <- ft |> add_header_row(\n",
    "      values = header_row_labels,\n",
    "      colwidths = col_widths\n",
    "    )\n",
    "    \n",
    "  # rebuild header row 1\n",
    "  header_row_labels <- c(\"\",\"\")\n",
    "  col_widths <- c(1,1)\n",
    "  for (i in seq_along(vars1)){\n",
    "    header_row_labels <- append(header_row_labels,vars1[i])\n",
    "    col_widths <- append(col_widths,var_levels[[i]])\n",
    "  }\n",
    "  ft <- ft |> add_header_row(\n",
    "      values = header_row_labels,\n",
    "      colwidths = col_widths\n",
    "    )\n",
    "  ft <- ft |> \n",
    "  align(\n",
    "    align = \"center\",\n",
    "    part = \"header\"\n",
    "  )  |>\n",
    "  bold(\n",
    "    bold = TRUE,\n",
    "    part = \"header\"\n",
    "  ) |>\n",
    "  bold(\n",
    "    j= 1:2,\n",
    "    part = \"body\"\n",
    "  )|> \n",
    "  align(\n",
    "    align = \"right\",\n",
    "    part = \"body\"\n",
    "  )\n",
    "\n",
    "  return(list(ft=ft,tib=tib))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "factorize_variables <- function(df_name,recode){\n",
    "  df<-get(df_name)\n",
    "  values<-recode[!is.na(recode$values), c('nvar','values')]\n",
    "  for (i in 1:nrow(values)){\n",
    "    var <- values[[i,'nvar']]\n",
    "    if (!var %in% names(df)){next }\n",
    "    values_  <- values[[i,'values']]\n",
    "    split_values  <- strsplit(values_,',')\n",
    "    numeric_values <- as.list(sapply(split_values, function(x) as.numeric(sub(\"(.*)=.*\", \"\\\\1\", x))))\n",
    "    character_values <- as.list( sapply(split_values, function(x) sub(\".*=(.*)\", \"\\\\1\", x)))\n",
    "    if (is.factor(df[[var]])){\n",
    "      df[[var]]<-droplevels(df[[var]])}\n",
    "      df[[var]]<-factor(df[[var]],levels=numeric_values,labels=character_values)\n",
    "    # print(paste('POST factorize_variables:',unique(df[['comp_mi']])))\n",
    "  }\n",
    "    # print(paste('PRE factorize_variables:',unique(df$evt_stk_mi_)))\n",
    "  \n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "relevel_variables <- function(df_name,recode){\n",
    "  df<-get(df_name)\n",
    "  # print(paste(names(df)))\n",
    "  values<-recode[!is.na(recode$relevel), c('nvar','relevel','values')]\n",
    "  # print(values)\n",
    "  if (nrow(values)>0){\n",
    "    for (i in 1:nrow(values)){\n",
    "      var <- values[[i,'nvar']]\n",
    "      relevel_ <- values[[i,'relevel']]\n",
    "      values_  <- values[[i,'values']]\n",
    "      split_values  <- strsplit(values_,',')\n",
    "      numeric_values <- as.list(sapply(split_values, function(x) as.numeric(sub(\"(.*)=.*\", \"\\\\1\", x))))\n",
    "      character_values <- as.list( sapply(split_values, function(x) sub(\".*=(.*)\", \"\\\\1\", x)))\n",
    "      # print(paste('relevel_variables:',var,relevel,split_values,numeric_values))\n",
    "      # print(names(df)[names(df)==var])\n",
    "      if(length(which(numeric_values==relevel_))>0){\n",
    "        df[[var]]<-relevel(df[[var]],ref=character_values[[which(numeric_values == relevel_)]])\n",
    "        # print(levels(df[[var]]))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load_recode <- function(original_sheet, recode_sheet) {\n",
    "  recode <- dplyr::bind_rows(original_sheet, recode_sheet)\n",
    "  recode <- filter(recode, !is.na(nvar))\n",
    "  duplicates <- recode[duplicated(recode$nvar),]\n",
    "  if (nrow(duplicates)>0){\n",
    "    stop(paste('ERROR :: DUPLICATES:',nrow(duplicates)))  \n",
    "  }\n",
    "  return(recode)\n",
    "}\n",
    "\n",
    "rename_variables <- function(df, recode, args) {\n",
    "  data_name <- args[[1]]\n",
    "  temp_recode <- recode |> filter(f == data_name)\n",
    "  for (i in 1:nrow(temp_recode)) {\n",
    "    r <- temp_recode[i,]\n",
    "    if(!is.na(r[['nvar']])){\n",
    "      df[[r[['nvar']]]] <- df[[r[['var']]]]\n",
    "    } \n",
    "    else {\n",
    "      print(paste('ERROR :: no nvar for',r[['var']]))\n",
    "    }\n",
    "  }\n",
    "  missing_columns <- !temp_recode[['nvar']] %in% names(df)\n",
    "  if(any(missing_columns)) {\n",
    "    print(paste('ERR: Missing columns >>',temp_recode[['nvar']][missing_columns]))\n",
    "  }\n",
    "  \n",
    "  # only include renamed columns\n",
    "  temp_recode <- temp_recode[!temp_recode[['nvar']] %in% temp_recode[['nvar']][missing_columns], ]\n",
    "  df_out <- df[temp_recode[['nvar']]]\n",
    "  return(df_out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fix_formulas <- function(recode,patterns){\n",
    "  recode$newfx <- NA\n",
    "  calc_columns <- recode[(recode['isfx']==1) & (!is.na(recode['isfx'])),]\n",
    "  if(nrow(calc_columns)>0){\n",
    "    for (i in 1:nrow(calc_columns)){\n",
    "      fx<-fix_forumla(fx=calc_columns[[i,'fx']],patterns=patterns)\n",
    "      recode$newfx[recode$var==calc_columns[[i,'nvar']]]<-fx    \n",
    "    }\n",
    "  }\n",
    "  return(recode)\n",
    "}\n",
    "\n",
    "reload_recode <- function(df,recode,args){\n",
    "  data_name <- args[[1]]\n",
    "  calc_columns <- recode[(recode['isfx']==1) & !is.na(recode['isfx']) & (recode['f']==data_name),]\n",
    "  if(nrow(calc_columns)>0){\n",
    "    for (i in 1:nrow(calc_columns)){      \n",
    "      df<-add_forumla_variable(fx=calc_columns[[i,'newfx']],var_name=calc_columns[[i,'nvar']],df=df)\n",
    "    }\n",
    "  }\n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# recode_list_old<-function(recode,analysis,i,doc){\n",
    "#     result<-lapply(analysis[['1']],function(x){\n",
    "#     matches <- regmatches(x,gregexpr(\"[\\\\$#]([0-9]+)\",x))[[1]]\n",
    "#     if(length(matches) > 0) {\n",
    "#         return(matches)\n",
    "#       } else {\n",
    "#         return(NULL)\n",
    "#       }\n",
    "#     })\n",
    "#     found <- gsub(\"\\\\$\",\"\",result[sapply(result, function(x) !is.null(x))]|> \n",
    "#       unlist()) |> \n",
    "#       tibble()\n",
    "#     names(found)[1]<- 'id'\n",
    "#     temp_recode <- mutate(recode,id=as.character(id))\n",
    "#     working_recode<-left_join(found,temp_recode,by='id')\n",
    "\n",
    "#     doc <- add_text(doc, 'Selected Variables')\n",
    "#     doc <- body_add_table(doc,working_recode[!is.na(working_recode$newfx),c(\"var\",\"newfx\")])\n",
    "#     doc <- body_add_break(doc)\n",
    "    \n",
    "    \n",
    "#     doc <- add_text(doc, 'All Variables')\n",
    "#     doc <- body_add_table(doc,recode[!is.na(recode$newfx),c(\"var\",\"newfx\")])\n",
    "#     doc <- body_add_break(doc)\n",
    "#   return(doc)\n",
    "# }\n",
    "recode_list <- function(path,doc){\n",
    "  # print(path)\n",
    "  definitions <- tryCatch({\n",
    "    py$get_var_list(path)\n",
    "  }, error = function(e) {\n",
    "    stop(\"Error in executing Python code: \", e$message)\n",
    "  })\n",
    "  # definitions <- py$get_var_list(path)\n",
    "  \n",
    "  # print(length(definitions))\n",
    "  # print(nrow(definitions))\n",
    "  if (nrow(definitions)>0){\n",
    "    for (i in 1:nrow(definitions)) {\n",
    "      tryCatch({\n",
    "        doc <- add_text(doc,definitions$var[i],level=3)       \n",
    "        for (split in strsplit(definitions[i,]$definition,'\\n')[[1]]){\n",
    "          # print(split)\n",
    "          doc <- add_text(doc,split,level=9) \n",
    "        }\n",
    "        doc <- body_add_par(doc,value='')\n",
    "      }, error = function(e){\n",
    "        print(paste('problem with python definitions',e$mesage))\n",
    "      })\n",
    "    }\n",
    "  }\n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "find_all_paths <- function(x, value, path = \"\") {\n",
    "  paths <- list()\n",
    "  \n",
    "  if (is.list(x)) {\n",
    "    for (name in names(x)) {\n",
    "      new_path <- if (path == \"\") name else paste(path, name, sep = \"$\")\n",
    "      result <- find_all_paths(x[[name]], value, new_path)\n",
    "      if (length(result) > 0) paths <- c(paths, result)\n",
    "    }\n",
    "  } else if (x == value) {\n",
    "    paths <- c(paths, path)\n",
    "  }\n",
    "  \n",
    "  return(paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "find_label <- function(var){\n",
    "  return(recode[recode$nvar == var, \"label\"][[1]])\n",
    "}\n",
    "\n",
    "labelit <- function(ft,recode,args){\n",
    "  # print(ft)\n",
    "  labels = (recode[recode$nvar %in% args, \"label\"])$label\n",
    "  if (length(labels)!= length(args)) {\n",
    "    if (any(duplicated(vars_list))){\n",
    "      print(paste('duplicated:',vars_list[duplicated(vars_list)]))\n",
    "    } else {\n",
    "      print('ERROR: not all args found in recode')\n",
    "    }\n",
    "  }\n",
    "  names(labels) = as.list(args)\n",
    "  ft <- labelizor(\n",
    "    x = ft, j = c(\"label\"),\n",
    "    labels = labels\n",
    "  )\n",
    "  # print(ft)\n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "get_args <-function(tib_row,n_args,n__args,patterns,do_eval=TRUE,quote_var= TRUE){\n",
    "  args <- list()\n",
    "  if (n_args > 0){\n",
    "    for (i in 1:n_args){\n",
    "      arg <- tib_row[[as.character(i)]]\n",
    "        \n",
    "      arg <- fix_forumla(fx=arg,patterns=patterns,quote_var=quote_var)  \n",
    "      arg <- gsub(\" \",\"\",arg)\n",
    "      if (do_eval == TRUE) {  \n",
    "        tryCatch({\n",
    "            arg <- eval(parse(text = arg))\n",
    "          },error = function(e) {\n",
    "            # print(arg)\n",
    "            stop(paste('arg:',arg,' e:',e))\n",
    "          })\n",
    "      }\n",
    "      args[[i]]<- arg\n",
    "    }\n",
    "  }\n",
    "  if (n__args > 0){\n",
    "    for (i in 1:n__args){\n",
    "        args[[n_args+i]]<- tib_row[[paste0(\"_\",i)]]\n",
    "    }\n",
    "  }\n",
    "  return(args) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# analysis_row<-analysis[i,]\n",
    "\n",
    "# tib_row<-analysis_row\n",
    "# df_name<-analysis_row[['in']]\n",
    "# # print(df_name)\n",
    "# formula_obj<-get_args(tib_row,1,0,patterns,do_eval=TRUE,quote_var=FALSE)[[1]]\n",
    "# arg1 <- regmatches(tib_row['1'], regexec(\"~(.*)\", tib_row['1']))[[1]][2]\n",
    "# var_oc <- regmatches(tib_row['1'], regexec(\"\\\\$(.*)~\", tib_row['1']))[[1]][2]\n",
    "# var_oc<-gsub(\" \",\"\",var_oc)\n",
    "# temp<-unique(regmatches(arg1, gregexpr(\"\\\\$\\\\w+\", arg1))[[1]])\n",
    "# add_args<-parse_json(tib_row[['2']])\n",
    "# if ('var' %in% names(add_args)) {\n",
    "#   var_pred <- add_args$var\n",
    "# } else {\n",
    "#   var_pred <- 'all'\n",
    "# }\n",
    "\n",
    "# tib_row['2']<-paste0(\"c(\", paste(temp, collapse = \", \"), \")\")\n",
    "# args2<-get_args(tib_row,2,1,patterns,do_eval=FALSE)\n",
    "# args3<-get_args(tib_row,2,1,patterns,do_eval=FALSE)\n",
    "# label_to_keep <- recode[recode$nvar == var_pred,]$label\n",
    "# levels_of_label_to_keep <- length(levels(ept(analysis_row[['in']])[[var_pred]]))\n",
    "# vars_list<-args2[[2]]\n",
    "# model <- args2[[3]]\n",
    "# var_list_parsed<-setdiff(ept(vars_list),var_pred)\n",
    "# label_list <-lapply(ept(vars_list),make_match)\n",
    "# title <- get_title(analysis_row)\n",
    "\n",
    "#   lower_threshold <- 0.01\n",
    "#   upper_threshold <- 100\n",
    "  \n",
    "#   df<-get(df_name)\n",
    "#   model <- glm(formula_obj,data=df,family=binomial)\n",
    "# # print(model)\n",
    "#   # coeff_df <- as.data.frame(formatC(summary(glm_obj)$coefficients, format = 'fg', digits = 3))\n",
    "#   # coeff_df <- tibble::rownames_to_column(coeff_df, var = \"Variable\")\n",
    "#   # ft_coeff <- qflextable(coeff_df)\n",
    "  \n",
    "#   #   coeff_df <- as.data.frame(formatC(vif(glm_obj), format = 'fg', digits = 3))\n",
    "#   # coeff_df <- tibble::rownames_to_column(coeff_df, var = \"Variable\")\n",
    "#   #  names(coeff_df)[2]<- \"VIF\"\n",
    "#   # ft_coeff <- qflextable(coeff_df)\n",
    "  \n",
    "#   #   varI <- varImp(glm_obj)\n",
    "#   # varI$Overall<- formatC(varI$Overall, format = 'fg',  digits = 2)\n",
    "#   # varI <- tibble::rownames_to_column(varI, var = \"Variable\")\n",
    "#   # ft_coeff <- qflextable(varI)\n",
    "#   # debug(broom::tidy)\n",
    "# suppressWarnings(tbl_regression(\n",
    "#       model,\n",
    "#       exponentiate = TRUE,\n",
    "#       label= label_list\n",
    "#     ))\n",
    "#   # undebug(broom::tidy)\n",
    "#   # output<-capture.output(suppressWarnings(tbl_regression(\n",
    "#   #     df,\n",
    "#   #     exponentiate = TRUE,\n",
    "#   #     label= label_list\n",
    "#   #   )))\n",
    "#     # print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# analysis_row<-analysis[i,]\n",
    "# analysis_row[['1']]\n",
    "# gsub('\\\\$','',analysis_row[['1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# analysis_row <- analysis[i,]\n",
    "# tib_row<-analysis_row\n",
    "#   df_name<-analysis_row[['in']]\n",
    "#   formula_obj<-get_args(tib_row,1,0,patterns,do_eval=TRUE,quote_var=FALSE)[[1]]\n",
    "#   arg1 <- regmatches(tib_row['1'], regexec(\"~(.*)\", tib_row['1']))[[1]][2]\n",
    "#   var_oc <- regmatches(tib_row['1'], regexec(\"\\\\$(.*)~\", tib_row['1']))[[1]][2]\n",
    "#   var_oc<-gsub(\" \",\"\",var_oc)\n",
    "#   temp<-unique(regmatches(arg1, gregexpr(\"\\\\$\\\\w+\", arg1))[[1]])\n",
    "#   add_args<-parse_json(tib_row[['2']])\n",
    "#   if ('var' %in% names(add_args)) {\n",
    "#     var_pred <- add_args$var\n",
    "#   } else {\n",
    "#     var_pred <- 'all'\n",
    "#   }\n",
    "  \n",
    "#   tib_row['2']<-paste0(\"c(\", paste(temp, collapse = \", \"), \")\")\n",
    "#   args2<-get_args(tib_row,2,1,patterns,do_eval=FALSE)\n",
    "#   args3<-get_args(tib_row,2,1,patterns,do_eval=FALSE)\n",
    "#   label_to_keep <- recode[recode$nvar == var_pred,]$label\n",
    "#   levels_of_label_to_keep <- length(levels(ept(analysis_row[['in']])[[var_pred]]))\n",
    "#   vars_list<-args2[[2]]\n",
    "#   model <- args2[[3]]\n",
    "#   var_list_parsed<-setdiff(ept(vars_list),var_pred)\n",
    "#   label_list <-lapply(ept(vars_list),make_match)\n",
    "#   title <- get_title(analysis_row)\n",
    "\n",
    "#   # add n\n",
    "#   glm_model_eq <- gsub('\\\\$','',analysis_row[['1']])\n",
    "\n",
    "#   # doc <- freq_list(df_name,ept(vars_list),doc)\n",
    "\n",
    "#   # print(var_pred),va\n",
    "#   # doc <- gt_glm(df_name,formula_obj,var_pred,vars_list,label_list,model,title,doc)\n",
    "  \n",
    "#   # if ('interaction' %in% names(add_args) &&  add_args$interaction == TRUE){\n",
    "#     df<-get(df_name)\n",
    "#     df$pred <- as.numeric(df[[var_pred]])\n",
    "#     df$oc <- df[[var_oc]]\n",
    "#     var_pred_label<-get_label(var_pred)\n",
    "#     var_list_parsed_label<-get_label(var_list_parsed)\n",
    "#     var_oc_label<-get_label(var_oc)\n",
    "  \n",
    "#   # model\n",
    "#     df$modx <- df[['sex']]\n",
    "#     if (model == 'binomial') {\n",
    "#       result<-suppressWarnings(glm(oc~modx*pred,data=df,family=binomial()))\n",
    "#     } else {\n",
    "#       result<-suppressWarnings(glm(oc~modx*pred,data=df,family=model))\n",
    "#     }\n",
    "#     get_coefficients(result)\n",
    "#     # suppressWarnings(lapply(var_list_parsed,print_interactions,df=df,var_pred=var_pred,var_oc=var_oc,doc=doc))\n",
    "#   # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "decimal_format <- function(x) {\n",
    "  if (is.numeric(x)) {\n",
    "    format(round(x, 2), nsmall = 2)\n",
    "  } else {\n",
    "    x\n",
    "  }\n",
    "}\n",
    "get_coefficients <- function(model){\n",
    "  # Extract coefficients and standard errors\n",
    "  summary_model <- summary(model)\n",
    "  coefficients <- summary_model$coefficients\n",
    "\n",
    "  # Get exponentiated coefficients (Odds Ratios)\n",
    "  odds_ratios <- exp(coefficients[, 1])\n",
    "\n",
    "  # Get confidence intervals\n",
    "  # conf_intervals <- confint(model)\n",
    "  # print(conf_intervals)\n",
    "  conf_intervals_default <- confint.default(model)\n",
    "  \n",
    "  # Extract p-values\n",
    "  p_values <- coefficients[, 4]\n",
    "\n",
    "  # Combine all components into a data frame\n",
    "  results <- data.frame(\n",
    "    Term = rownames(coefficients),\n",
    "    Estimate = coefficients[, 1],\n",
    "    StdError = coefficients[, 2],\n",
    "    OR = odds_ratios,\n",
    "    # CI_Low_LL = conf_intervals[, 1],\n",
    "    # CI_High_LL = conf_intervals[, 2],\n",
    "    CI_Low_Wald = conf_intervals_default[, 1],\n",
    "    CI_High_Wald = conf_intervals_default[, 2],\n",
    "    PValue = p_values\n",
    "  )\n",
    "  results_formatted <- as.data.frame(lapply(results, decimal_format))\n",
    "\n",
    "  # coeff_df <- as.data.frame(formatC(results, format = 'fg', digits = 3))\n",
    "  coeff_df <- tibble::rownames_to_column(results_formatted, var = \"Variable\")\n",
    "  return(coeff_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gt_glm_shell <- function(recode,analysis_row,n_args,n__args,patterns,doc){\n",
    "\n",
    "  tib_row<-analysis_row\n",
    "  df_name<-analysis_row[['in']]\n",
    "  formula_obj<-get_args(tib_row,1,0,patterns,do_eval=TRUE,quote_var=FALSE)[[1]]\n",
    "  arg1 <- regmatches(tib_row['1'], regexec(\"~(.*)\", tib_row['1']))[[1]][2]\n",
    "  var_oc <- regmatches(tib_row['1'], regexec(\"\\\\$(.*)~\", tib_row['1']))[[1]][2]\n",
    "  var_oc<-gsub(\" \",\"\",var_oc)\n",
    "  temp<-unique(regmatches(arg1, gregexpr(\"\\\\$\\\\w+\", arg1))[[1]])\n",
    "  add_args<-parse_json(tib_row[['2']])\n",
    "  if ('var' %in% names(add_args)) {\n",
    "    var_pred <- add_args$var\n",
    "  } else {\n",
    "    var_pred <- 'all'\n",
    "  }\n",
    "  \n",
    "  tib_row['2']<-paste0(\"c(\", paste(temp, collapse = \", \"), \")\")\n",
    "  args2<-get_args(tib_row,2,1,patterns,do_eval=FALSE)\n",
    "  args3<-get_args(tib_row,2,1,patterns,do_eval=FALSE)\n",
    "  label_to_keep <- recode[recode$nvar == var_pred,]$label\n",
    "  levels_of_label_to_keep <- length(levels(ept(analysis_row[['in']])[[var_pred]]))\n",
    "  vars_list<-args2[[2]]\n",
    "  model <- args2[[3]]\n",
    "  var_list_parsed<-setdiff(ept(vars_list),var_pred)\n",
    "  label_list <-lapply(ept(vars_list),make_match)\n",
    "  title <- get_title(analysis_row)\n",
    "\n",
    "  # add n\n",
    "  glm_model_eq <- gsub('\\\\$','',analysis_row[['1']])\n",
    "  doc <- add_text(doc, title,level=2  )\n",
    "  doc <- add__n(df_name,doc,paste(glm_model_eq))\n",
    "  doc <- body_add_flextable(doc, get_summary_df(get(df_name), ept(vars_list))) \n",
    "    \n",
    "  # doc <- freq_list(df_name,ept(vars_list),doc)\n",
    "\n",
    "  # print(var_pred),va\n",
    "  doc <- gt_glm(df_name,formula_obj,var_pred,vars_list,label_list,model,title,doc)\n",
    "  \n",
    "  if ('interaction' %in% names(add_args) &&  add_args$interaction == TRUE){\n",
    "    df<-get(df_name)\n",
    "    df$pred <- as.numeric(df[[var_pred]])\n",
    "    df$oc <- df[[var_oc]]\n",
    "    suppressWarnings(lapply(var_list_parsed,print_interactions,df=df,var_pred=var_pred,var_oc=var_oc,model=model,doc=doc))\n",
    "  }\n",
    "  \n",
    "  # report interactions\n",
    "#  if (add_args$interactions == TRUE) {\n",
    "#   models<-paste0(var_oc,'~',var_list_parsed,'*',var_pred)\n",
    "# }\n",
    "  \n",
    "  return(doc)\n",
    "}\n",
    "gt_glm <- function(df_name,formula_obj,var_pred,vars_list,label_list,model,title,doc){\n",
    "  doc <- body_add_break(doc)\n",
    "  # doc <- add_text_(doc, title)\n",
    "  lower_threshold <- 0.01\n",
    "  upper_threshold <- 100\n",
    "  \n",
    "  # print(paste('gt_glm input:',df_name,formula_obj,var_pred,vars_list,model,collapse=' '))\n",
    "  df<-get(df_name)\n",
    "  glm_obj <- suppressWarnings(glm(formula_obj,data=df,family=binomial))\n",
    "  \n",
    "  # add coeff to doc\n",
    "  # coeff_df <- as.data.frame(formatC(summary(glm_obj)$coefficients, format = 'fg', digits = 3))\n",
    "  # coeff_df <- tibble::rownames_to_column(coeff_df, var = \"Variable\")\n",
    "  # ft_coeff <- qflextable(coeff_df)\n",
    "  ft_coeff <- qflextable(get_coefficients(glm_obj))\n",
    "  doc <- add_text(doc, 'coefficients', level=3)\n",
    "  doc <- body_add_flextable(doc, ft_coeff)\n",
    "  doc <- body_add_par(doc, '')\n",
    "  \n",
    "  # add multicollinearity to doc\n",
    "  coeff_df <- as.data.frame(formatC(vif(glm_obj), format = 'fg', digits = 3))\n",
    "  coeff_df <- tibble::rownames_to_column(coeff_df, var = \"Variable\")\n",
    "   names(coeff_df)[2]<- \"VIF\"\n",
    "  ft_coeff <- qflextable(coeff_df)\n",
    "  doc <- add_text(doc, 'multicollinearity',level=3)\n",
    "  doc <- body_add_flextable(doc, ft_coeff)\n",
    "  doc <- body_add_par(doc, '')\n",
    "  \n",
    "  # add variable importance to doc\n",
    "  varI <- varImp(glm_obj)\n",
    "  varI$Overall<- formatC(varI$Overall, format = 'fg',  digits = 2)\n",
    "  varI <- tibble::rownames_to_column(varI, var = \"Variable\")\n",
    "  ft_coeff <- qflextable(varI)\n",
    "  doc <- add_text(doc, 'variable importance',level=3)\n",
    "  doc <- body_add_flextable(doc, ft_coeff)\n",
    "  doc <- body_add_par(doc, '')\n",
    "  \n",
    "  # Print the exponentiated coefficients\n",
    "  # print(ft_coeff)\n",
    "  \n",
    "  output<-capture.output(suppressWarnings(tbl_regression(\n",
    "      glm_obj,\n",
    "      exponentiate = TRUE,\n",
    "      label= label_list\n",
    "    )))\n",
    "    # print(output)\n",
    "  \n",
    "  footer <- 'OR estimates using Likelihood method'\n",
    "    \n",
    "  if (any(grepl(\"Error in confint\", output))) {\n",
    "    print('OR estimates Likelihood not stable, so using Wald')\n",
    "    footer <- 'OR estimates Likelihood not stable, so using Wald'\n",
    "    # doc<- doc |> add_text(\"OR estimates Likelihood not stable, so using Wald\",level=8,type='note')\n",
    "  }   \n",
    "  \n",
    "  gt<- suppressWarnings(glm_obj |>\n",
    "    tbl_regression(\n",
    "      exponentiate = TRUE,\n",
    "      label= label_list\n",
    "    ) |> \n",
    "    bold_p()|>\n",
    "    add_nevent(location = \"level\") |>\n",
    "    add_n(location = \"level\") %>%\n",
    "    # adding event rate\n",
    "    modify_table_body(\n",
    "      ~ .x %>%\n",
    "        dplyr::mutate(\n",
    "          stat_nevent_rate = \n",
    "            ifelse(\n",
    "              !is.na(stat_nevent),\n",
    "              paste0(style_sigfig(stat_nevent / stat_n, scale = 100), \"%\"),\n",
    "              NA\n",
    "            ), \n",
    "          .after = stat_nevent\n",
    "        ) %>%\n",
    "        dplyr::mutate(\n",
    "          estimate = ifelse(estimate < lower_threshold | estimate > upper_threshold, NA, estimate)\n",
    "        )%>%\n",
    "        dplyr::mutate(\n",
    "          ci = ifelse(ci < lower_threshold | ci > upper_threshold, NA, ci)\n",
    "        )\n",
    "    ) %>%\n",
    "    # merge the colums into a single column\n",
    "    modify_column_merge(\n",
    "      pattern = \"{stat_nevent} / {stat_n} ({stat_nevent_rate})\",\n",
    "      rows = !is.na(stat_nevent)\n",
    "    ) %>%\n",
    "    # update header to event rate\n",
    "    modify_header(stat_nevent = \"**Event Rate**\"))\n",
    "  \n",
    "  \n",
    "  if (var_pred!='all'){\n",
    "    print(paste('var_pred:',var_pred))\n",
    "    gt$table_body<-slice(gt$table_body,which(gt$table_body$variable==var_pred))\n",
    "  }\n",
    "  ft <- gt |> \n",
    "    as_flex_table() \n",
    "  \n",
    "  if (var_pred!='all'){\n",
    "    var_list_parsed<-ept(vars_list)\n",
    "    var_list_parsed<-var_list_parsed[var_list_parsed!=var_pred]\n",
    "    var_list_labels<-lapply(var_list_parsed,get_label)\n",
    "    footer_text <- str_to_sentence(paste(\"Adjusted for\",paste(var_list_labels,collapse = ', ')))\n",
    "    ft <- ft |>\n",
    "      add_footer_lines(c(footer_text,footer))\n",
    "  }  else {\n",
    "    ft <- ft |>\n",
    "      add_footer_lines(c(footer))\n",
    "  }\n",
    "\n",
    "  doc <- body_add_flextable(doc, ft)\n",
    "  return(doc)\n",
    "}\n",
    "\n",
    "\n",
    "print_interactions <- function(var_list_parsed,df,var_pred,var_oc,model,doc){\n",
    "  # print(paste('VAR_LIST_PARSED>>',var_list_parsed))\n",
    "  # print(grep('oc',names(df),value=TRUE))\n",
    "  # print(paste('print_interactions input:',var_list_parsed,var_pred,var_oc))\n",
    "  \n",
    " \n",
    "  # get label names\n",
    "  var_pred_label<-get_label(var_pred)\n",
    "  var_list_parsed_label<-get_label(var_list_parsed)\n",
    "  var_oc_label<-get_label(var_oc)\n",
    "  \n",
    "  # model\n",
    "  df$modx <- df[[var_list_parsed]]\n",
    "  if (model == 'binomial') {\n",
    "    result<-suppressWarnings(glm(oc~modx*pred,data=df,family=binomial()))\n",
    "  } else {\n",
    "    result<-suppressWarnings(glm(oc~modx*pred,data=df,family=model))\n",
    "  }\n",
    "  coefficients <- result$coefficients\n",
    "  ft_coeff <- qflextable(get_coefficients(result))\n",
    "  doc <- add_text(doc, paste(var_pred,' * ',var_list_parsed),level=3)\n",
    "  doc <- body_add_flextable(doc, ft_coeff)\n",
    "  doc <- body_add_par(doc, '')\n",
    "  \n",
    "  # results\n",
    "  tib<- enframe(coefficients,name=\"interaction\",value='value')\n",
    "  tib$value<-sapply(tib$value, function(x){\n",
    "    formatC(x, format = \"f\", digits = 2)\n",
    "  })\n",
    "  # flextable\n",
    "  ft <- flextable(tib) |>\n",
    "    set_widths(col1=2,other_cols=1.5)\n",
    "  title<-paste0('Interaction between ',var_pred_label,' and ',var_list_parsed_label,' for ',var_oc_label)\n",
    "  doc<-doc|>\n",
    "    body_add_break()|>\n",
    "    add_text(title,level =2)|>\n",
    "    body_add_flextable(ft)\n",
    "    \n",
    "    \n",
    "  # plot\n",
    "  temp_plot <- paste0(\"crest_analysis/interaction_plot.png\")\n",
    "  plot<-suppressWarnings(interact_plot(result, pred = pred, \n",
    "    modx = modx,\n",
    "    interval = TRUE,\n",
    "    legend.main = var_list_parsed_label,\n",
    "    x.label = var_pred_label,\n",
    "    y.label = var_oc_label\n",
    "  ))\n",
    "  ggsave(temp_plot, width = 6, height = 4, dpi = 300) \n",
    "  doc<-doc|>\n",
    "    body_add_img(src = temp_plot, width = 6, height = 4) \n",
    "  \n",
    "  plot<-suppressWarnings(interact_plot(result, pred = pred, \n",
    "    modx = modx,\n",
    "    interval = TRUE,\n",
    "    linearity.check = TRUE,\n",
    "    legend.main = var_list_parsed_label,\n",
    "    x.label = var_pred_label,\n",
    "    y.label = var_oc_label\n",
    "  ))\n",
    "  ggsave(temp_plot, width = 6, height = 4, dpi = 300)\n",
    "  doc<-doc|>\n",
    "    body_add_img(src = temp_plot, width = 6, height = 4) \n",
    "    \n",
    "  # simple slopes\n",
    "  slopes<-suppressWarnings(sim_slopes(result, pred = pred, modx = modx, robust = \"HC3\"))\n",
    "  slopes$slopes <- data.frame(lapply(slopes$slopes, function(x)  {\n",
    "    x[x<.001]<-0\n",
    "    formatC(x, format = 'fg', digits = 3)\n",
    "    } ))\n",
    " \n",
    "   ft<-flextable(slopes$slopes)\n",
    "  # disp(to_html(ft))\n",
    "  doc<-doc|>\n",
    "    add_text(\"SLOPE ANALYSIS\",level =9) |>\n",
    "    body_add_flextable(ft)\n",
    "    \n",
    "  if (length(slopes$jn)>0){  \n",
    "    print(comma_sep_list(slopes$jn[[1]]$bounds))\n",
    "   doc <- doc |> add_text(comma_sep_list(slopes$jn[[1]]$bounds),level =9) \n",
    "  }\n",
    "  return(doc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check if a variable is continuous\n",
    "is_continuous <- function(var) {\n",
    "  return(is.numeric(var))\n",
    "}\n",
    "\n",
    "# Function to check if a variable is categorical\n",
    "is_categorical <- function(var) {\n",
    "  return(is.factor(var) || is.character(var))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "get_summary_df <- function(df, vars_list) {\n",
    "  #  type <-sapply(df[vars_list], function(x) {\n",
    "  #     if (is_continuous(x)) {\n",
    "  #       return(\"Continuous\")\n",
    "  #     } else if (is_categorical(x)) {\n",
    "  #       return(\"Categorical\")\n",
    "  #     } else {\n",
    "  #       return(\"Other\")\n",
    "  #     }\n",
    "  #   })\n",
    "    \n",
    "  # print(type)\n",
    "  \n",
    "  # Create a summary data frame\n",
    "  summary_df <- data.frame(\n",
    "    Variable = vars_list,\n",
    "    Type = sapply(df[vars_list], function(x) {\n",
    "      if (is_continuous(x)) {\n",
    "        return(\"Continuous\")\n",
    "      } else if (is_categorical(x)) {\n",
    "        return(\"Categorical\")\n",
    "      } else {\n",
    "        return(\"Other\")\n",
    "      }\n",
    "    }),\n",
    "    Missing = sapply(df[vars_list], function(x) sum(is.na(x)))\n",
    "  )\n",
    "\n",
    "  # Create a flextable\n",
    "  ft <- flextable(summary_df) |>\n",
    "    fit_to_width(max_width = 3,unit = 'in')\n",
    "  \n",
    "  return(ft)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# analysis_row <- analysis[i,]\n",
    "#     processed_args <- get_args(analysis_row, 1, 3, patterns)\n",
    "#     tib_row <- analysis_row\n",
    "#     df_name<-analysis_row[['in']]\n",
    "#         add_args <- parse_json(tib_row[['2']])\n",
    "#     by_var <- add_args$var\n",
    "#     if ('strata' %in% names(add_args)) {\n",
    "#         strata_ <- add_args$strata\n",
    "#     } else {\n",
    "#       strata_ <- NULL\n",
    "#     }\n",
    "    \n",
    "#     vars_list <- processed_args[[1]]\n",
    "#     categorical <- tib_row[['_1']]\n",
    "#     continuous <- tib_row[['_2']]\n",
    "#     summary_type_continuous <- tib_row[['_3']]\n",
    "    \n",
    "#     doc <- add__n(df_name, doc)\n",
    "#     font_size <- tib_row[['font']]\n",
    "#     if (is.na(font_size)) {\n",
    "#         font_size <- 10\n",
    "#     }\n",
    "\n",
    "#     # if (exists(\"strata_\") & !is.null(strata_)) {\n",
    "#     #   # print(strata_)\n",
    "#     #   ft <- gt_tbl_summary_strata(df_name, vars_list, by_var, categorical, continuous, summary_type_continuous,strata_) |>\n",
    "#     #       set_widths(col1 = 2, other_cols = 0.75) |>\n",
    "#     #       labelit(recode, vars_list) |>\n",
    "#     #       fontsize(size = font_size)\n",
    "#     # } else {\n",
    "#       # ft <- gt_tbl_summary(df_name, vars_list, by_var, categorical, continuous,summary_type_continuous) |>\n",
    "#       #     set_widths(col1 = 2, other_cols = 0.75) |>\n",
    "#       #     labelit(recode, vars_list) |>\n",
    "#       #     fontsize(size = font_size)\n",
    "#     # }\n",
    "    \n",
    "#       df<-get(df_name)\n",
    "#   list_cont<-strsplit(continuous, \"\\\\|\")[[1]]\n",
    "#   # ft <-get_summary_df(df, vars_list)\n",
    "  \n",
    "\n",
    "# var_type_list <- lapply(vars_list, function(var) {\n",
    "#   if (is_continuous(df[[var]])) {\n",
    "#     return(as.formula(paste(var, \"~ 'continuous'\")))\n",
    "#   } else if (is_categorical(df[[var]])) {\n",
    "#     return(as.formula(paste(var, \"~ 'categorical'\")))\n",
    "#   } else {\n",
    "#     return(as.formula(paste(var, \"~ 'other'\")))\n",
    "#   }\n",
    "# })\n",
    "\n",
    "# statistic_list <- lapply(vars_list, function(var) {\n",
    "#   if (is_continuous(df[[var]])) {\n",
    "#     return(as.formula(paste(var, \"~ '\", list_cont,\"'\")))\n",
    "#   } else if (is_categorical(df[[var]])) {\n",
    "#     return(as.formula(paste(var, \"~ '\",categorical,\"'\")))\n",
    "#   } else {\n",
    "#     return(as.formula(paste(var, \"~ 'other'\")))\n",
    "#   }\n",
    "# })\n",
    "\n",
    "# # Define the correct statistic argument\n",
    "# # statistic_list <- list(\n",
    "# #   age = \"{mean} ({sd})\",\n",
    "# #   sex = \"{n} / {N} ({p}%)\",\n",
    "# #   race3 = \"{n} / {N} ({p}%)\",\n",
    "# #   smok = \"{n} / {N} ({p}%)\",\n",
    "# #   hl = \"{n} / {N} ({p}%)\",\n",
    "# #   htn = \"{n} / {N} ({p}%)\",\n",
    "# #   dm = \"{n} / {N} ({p}%)\",\n",
    "# #   stenosis70 = \"{n} / {N} ({p}%)\",\n",
    "# #   evt_type = \"{n} / {N} ({p}%)\",\n",
    "# #   dur_sch_to_evt_gp = \"{n} / {N} ({p}%)\",\n",
    "# #   cas_cea = \"{n} / {N} ({p}%)\"\n",
    "# # )\n",
    "\n",
    "# # Generate the summary table\n",
    "#   ft <- df |>\n",
    "#   select(all_of(vars_list)) |>\n",
    "# tbl_summary(\n",
    "#             by = {{ by_var }}, \n",
    "#             type = var_type_list, \n",
    "#             statistic = statistic_list,\n",
    "#             missing_text = \"(Missing)\", \n",
    "#             label= lapply(vars_list,make_match)\n",
    "# ) |>\n",
    "#   # ft <- df |>\n",
    "#   # select(all_of(vars_list)) |>\n",
    "#   # # https://rdrr.io/cran/gtsummary/man/tbl_summary.html for 2 rows check this out\n",
    "#   # tbl_summary(\n",
    "#   #   by = {{ by_var }},\n",
    "#   #   type = all_continuous() ~ summary_type_continuous,\n",
    "#   #   statistic = list(\n",
    "#   #     all_continuous() ~ list_cont,\n",
    "#   #     all_categorical() ~ categorical\n",
    "#   #   ),\n",
    "#   #   # missing = \"no\",\n",
    "#   #   missing_text = \"(Missing)\",\n",
    "#   #   label= lapply(vars_list,make_match)\n",
    "#   # ) |>\n",
    "#   add_p_() |>\n",
    "#   modify_caption(\"Patient Characteristics (N = {N})\") |>\n",
    "#   modify_spanning_header(all_stat_cols() ~ match_single(by_var)) |>\n",
    "#   as_flex_table() |>\n",
    "#   keep_with_next()\n",
    "# print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "`%||%` <- function(a, b) {\n",
    "  if (is.null(a)|is.na(a)) b else a\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "detailed_structure <- function(obj, level = 0) {\n",
    "  indent <- paste(rep(\"  \", level), collapse = \"\")\n",
    "  \n",
    "  cat(indent, \"Structure of object at level\", level, \":\\n\")\n",
    "  str(obj, max.level = 1)\n",
    "  \n",
    "  # If the object is a list or data frame, recursively check its elements\n",
    "  if (is.list(obj) || is.data.frame(obj)) {\n",
    "    cat(indent, \"Iterating over elements:\\n\")\n",
    "    for (name in names(obj)) {\n",
    "      cat(indent, \"- Element name:\", name, \"\\n\")\n",
    "      detailed_structure(obj[[name]], level + 1)\n",
    "    }\n",
    "  } else {\n",
    "    # cat(indent, \"Object is not a list or data frame, no further iteration.\\n\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ft$header$content$content$data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "  # ft <- df |>\n",
    "  # select(all_of(vars_list)) |>\n",
    "  # # https://rdrr.io/cran/gtsummary/man/tbl_summary.html for 2 rows check this out\n",
    "  # tbl_strata(\n",
    "  #   strata = {{ strata_ }},\n",
    "  #   ~.x |>\n",
    "  #   tbl_summary(\n",
    "  #     by = {{ by_var }},\n",
    "  #     type = var_type_list(df,vars_list),\n",
    "  #     statistic = statistic_list(df,vars_list,continuous,categorical),\n",
    "  #     missing_text = \"(Missing)\",\n",
    "  #     label= lapply(setdiff(vars_list, strata_),make_match)\n",
    "  # )) |>\n",
    "  # modify_header(all_stat_cols() ~ \"{level}\") |>\n",
    "  # add_p_() |>\n",
    "  # modify_caption(paste(title,\" Patient Characteristics (N = {N})\")) |>\n",
    "  # as_flex_table() |>\n",
    "  # keep_with_next()\n",
    "  # return(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gt_tbl_summary_strata <- function(df,vars_list,by_var,categorical,continuous,summary_type_continuous,strata_var,title){\n",
    "  # print(strata_var)\n",
    "  levels_ <- levels(df[[strata_var]])\n",
    "  df_split <- split(df, df[[strata_var]]) \n",
    "  levels_count <- length(levels_)\n",
    "  levels_n <- table(df[[strata_var]])\n",
    "  # header_text <- c('.',levels(df[[strata_var]]))\n",
    "  header_text <- c('.', paste0(levels_, \" (N=\", levels_n, \")\"))\n",
    "  strata_var_label <- find_label(strata_var)\n",
    "  # df_split[[strata_]]$strata <- paste(find_label(strata_), \"(\",df[[strata_]],\")\")\n",
    "  \n",
    "  ft_c<-NULL\n",
    "  first_loop <- TRUE\n",
    "  \n",
    "  for (strata_ in levels_) {\n",
    "    ft <- gt_tbl_summary(df_split[[strata_]], vars_list, by_var, categorical, continuous,summary_type_continuous,title,missing=\"always\", stratified = TRUE) \n",
    "    if (first_loop) {\n",
    "      ft_c <- ft_c_first(ft,strata_)\n",
    "    } else {\n",
    "      ft_c <- ft_c_others(ft_c,ft,strata_)\n",
    "    }\n",
    "    first_loop <- FALSE\n",
    "  }\n",
    "  \n",
    "  col_per_strata <- (ncol(ft_c$header$dataset)-1)/levels_count\n",
    "  \n",
    "  ft_c<-add_header_row(ft_c,values=header_text,colwidths = c(1,rep(col_per_strata,levels_count)))\n",
    "  ft_c<-add_header_row(ft_c,values=c('.',strata_var_label),colwidths = c(1,col_per_strata * levels_count))\n",
    "  \n",
    "  return(ft_c)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gt_tbl_summary_shell <- function(recode, analysis_row, n_args, n__args, patterns, doc) {\n",
    "    processed_args <- get_args(analysis_row, 1, 3, patterns)\n",
    "    tib_row <- analysis_row\n",
    "    df_name<-analysis_row[['in']]\n",
    "    \n",
    "    add_args <- parse_json(tib_row[['2']])\n",
    "    by_var <- add_args$var\n",
    "    if ('strata' %in% names(add_args)) {\n",
    "        strata_var <- add_args$strata\n",
    "    } else {\n",
    "      strata_var <- NULL\n",
    "    }\n",
    "    \n",
    "    vars_list <- processed_args[[1]]\n",
    "    categorical <- tib_row[['_1']]\n",
    "    continuous <- tib_row[['_2']]\n",
    "    summary_type_continuous <- tib_row[['_3']]\n",
    "    title <- tib_row[['title']] %||% \"--\"\n",
    "    \n",
    "    doc <- add__n(df_name, doc)\n",
    "    font_size <- tib_row[['font']]\n",
    "    if (is.na(font_size)) {\n",
    "        font_size <- 10\n",
    "    }\n",
    "    df<-get(df_name)\n",
    "\n",
    "    if (exists(\"strata_var\") & !is.null(strata_var)) {\n",
    "      # print(strata_)\n",
    "      ft <- gt_tbl_summary_strata(df, vars_list, by_var, categorical, continuous, summary_type_continuous,strata_var,title)\n",
    "      #  |>\n",
    "      #     set_widths(col1 = 2, other_cols = 0.75) |>\n",
    "      #     labelit(recode, vars_list) |>\n",
    "      #     fontsize(size = font_size)\n",
    "    } else {\n",
    "      ft <- gt_tbl_summary(df, vars_list, by_var, categorical, continuous,summary_type_continuous,title) |>\n",
    "          set_widths(col1 = 2, other_cols = 0.75) |>\n",
    "          labelit(recode, vars_list) |>\n",
    "          fontsize(size = font_size)\n",
    "    }\n",
    "    \n",
    "    # if (!is.na(tib_row[['title']])) {  \n",
    "    doc <- add_text(doc, title,level=2)\n",
    "    # }\n",
    "    doc <- body_add_flextable(doc, ft, split = TRUE)\n",
    "\n",
    "    doc <- body_add_break(doc)\n",
    "\n",
    "\n",
    "    return(doc)\n",
    "}\n",
    "\n",
    "make_match <- function(x) {\n",
    "  found<-(recode[recode$nvar == x, \"label\"])$label\n",
    "  ept(paste0(x,\"~ '\",found, \"'\"))\n",
    "}\n",
    "get_label <- function(x) {\n",
    "  if(is.vector(x)){\n",
    "    return((recode[recode$nvar %in% x, \"label\"])$label)\n",
    "  } else {\n",
    "    return((recode[recode$nvar == x, \"label\"])$label)\n",
    "  }\n",
    "}\n",
    "match_single <- function(x) {\n",
    "  (recode[recode$nvar == x, \"label\"])$label\n",
    "}\n",
    "keep_with_next <- function(ft) {\n",
    "  # print(ft$body[[8]]$pars$padding.left$data[,1])\n",
    "  indents <- unique(ft$body[[8]]$pars$padding.left$data[,1])\n",
    "  unindented <- min(indents)\n",
    "  indented<- max(indents)\n",
    "  for (r in 1:nrow( ft$body[[8]]$pars$padding.left$data)){\n",
    "    if (ft$body[[8]]$pars$padding.left$data[[r,1]]==indented){\n",
    "      ft$body[[8]]$pars$keep_with_next$data[[r,1]]<-TRUE\n",
    "      if(r>1){\n",
    "        ft$body[[8]]$pars$keep_with_next$data[[r-1,1]]<-TRUE\n",
    "      }\n",
    "    } else {\n",
    "      ft$body[[8]]$pars$keep_with_next$data[[r,1]]<-FALSE\n",
    "      if(r>1){\n",
    "        ft$body[[8]]$pars$keep_with_next$data[[r-1,1]]<-FALSE\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(ft)\n",
    "}\n",
    "\n",
    "add_p_ <- function(x){\n",
    "  tryCatch({\n",
    "    add_p(x,pvalue_fun = ~ style_pvalue(.x, digits = 2))} ,\n",
    "    error=function(e){\n",
    "      print('err')\n",
    "      return(x)\n",
    "    }\n",
    "  )\n",
    "  # return(add_p(x,pvalue_fun = ~ style_pvalue(.x, digits = 2)) )\n",
    "}\n",
    "\n",
    "var_type_list <-  function(df,var_list){\n",
    "    list_<-lapply(var_list, function(var) {\n",
    "    if (is_continuous(df[[var]])) {\n",
    "      return(as.formula(paste(var, \"~ 'continuous'\")))\n",
    "    } else if (is_categorical(df[[var]])) {\n",
    "      return(as.formula(paste(var, \"~ 'categorical'\")))\n",
    "    } else {\n",
    "      return(as.formula(paste(var, \"~ 'other'\")))\n",
    "    }\n",
    "  })\n",
    "  return(list_)\n",
    "}\n",
    "\n",
    "\n",
    "statistic_list <- function(df,var_list,continuous,categorical){\n",
    "    list_cont<-strsplit(continuous, \"\\\\|\")[[1]]\n",
    "    list_<-lapply(var_list, function(var) {\n",
    "    if (is_continuous(df[[var]])) {\n",
    "      return(as.formula(paste(var, \"~ '\", list_cont,\"'\")))\n",
    "    } else if (is_categorical(df[[var]])) {\n",
    "      return(as.formula(paste(var, \"~ '\",categorical,\"'\")))\n",
    "    } else {\n",
    "      return(as.formula(paste(var, \"~ 'other'\")))\n",
    "    }\n",
    "  })\n",
    "  return(list_)\n",
    "}\n",
    "\n",
    "gt_tbl_summary <- function(df,vars_list,by_var,categorical,continuous,summary_type_continuous,title,missing=\"always\",stratified = FALSE){\n",
    "#   print(title)\n",
    "# print(by_var)\n",
    "# print(vars_list)\n",
    "# print(continuous)\n",
    "# print(categorical)\n",
    "# print(missing)\n",
    "  # list_cont<-strsplit(continuous, \"\\\\|\")[[1]]\n",
    "  ft <- df |>\n",
    "  select(all_of(vars_list)) |>\n",
    "  # https://rdrr.io/cran/gtsummary/man/tbl_summary.html for 2 rows check this out\n",
    "  tbl_summary(\n",
    "    by = {{ by_var }},\n",
    "    type = var_type_list(df,vars_list),\n",
    "    statistic = statistic_list(df,vars_list,continuous,categorical),\n",
    "    missing = missing,\n",
    "    missing_text = \"(Missing)\",\n",
    "    label= lapply(vars_list,make_match)\n",
    "  ) |>\n",
    "  add_p_() |>\n",
    "  modify_spanning_header(all_stat_cols() ~ match_single(by_var)) \n",
    "  \n",
    "\n",
    "  if (!stratified) {\n",
    "    ft <- ft |>\n",
    "    modify_caption(paste(title,\" Patient Characteristics (N = {N})\")) \n",
    "  }\n",
    "  \n",
    "  ft <- ft |>\n",
    "    as_flex_table() |>\n",
    "    keep_with_next()\n",
    "  return(ft)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ft2<-ft1<-ft\n",
    "# ft1$strata <- '1_'\n",
    "# ft2$strata <- '2_'\n",
    "# ft_c<-NULL\n",
    "# Assuming ft1 and ft2 are already defined flextables\n",
    "# Remove the first column from ft2's body and header content\n",
    "\n",
    "# Remove the first column key and column width from ft2\n",
    "ft_c_first <- function(ft,strata_){\n",
    "  ft$col_keys <- paste0(strata_,'||',ft$col_keys)\n",
    "  for (part in c(\"header\", \"body\", \"footer\")) {\n",
    "    for (prop in c(\"dataset\", \"col_keys\", \"colwidth\", \"colwidths\")) {\n",
    "      if (is.null(names(ft[[part]][[prop]]))){\n",
    "        ft[[part]][[prop]] <- paste0(strata_,'||',ft[[part]][[prop]])\n",
    "      }  else {\n",
    "        ft[[part]][[prop]] <- ft[[part]][[prop]]\n",
    "      }\n",
    "      \n",
    "      if (is.vector(ft[[part]][[prop]])) {\n",
    "        names(ft[[part]][[prop]]) <- paste0(strata_,'||', names(ft[[part]][[prop]]))\n",
    "      } else if (is.data.frame(ft[[part]][[prop]])) {\n",
    "        colnames(ft[[part]][[prop]]) <- paste0(strata_,'||', colnames(ft[[part]][[prop]]))\n",
    "      }\n",
    "    }\n",
    "    ft[[part]]$content$keys <- paste0(strata_,'||',ft[[part]]$content$keys)\n",
    "    colnames(ft[[part]]$content$data) <- paste0(strata_,'||',colnames(ft[[part]]$content$data))\n",
    "\n",
    "    for (prop_lvl_1 in names(ft[[part]]$styles)){\n",
    "      for (prop_lvl_2 in names(ft[[part]]$styles[[prop_lvl_1]])){\n",
    "        ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['keys']] <-  \n",
    "          paste0(strata_,'||',ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['keys']])\n",
    "        colnames(ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$data) <- \n",
    "          paste0(strata_,'||',colnames(ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$data))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(ft)\n",
    "}\n",
    "\n",
    "ft_c_other <- function(ft,strata_){\n",
    "  ft$col_keys <- paste0(strata_,'||',ft$col_keys[-1])\n",
    "  for (part in c(\"header\", \"body\", \"footer\")) {\n",
    "    for (prop in c(\"dataset\", \"col_keys\", \"colwidth\", \"colwidths\")) {\n",
    "      if (is.null(names(ft[[part]][[prop]]))){\n",
    "        ft[[part]][[prop]] <- paste0(strata_,'||',ft[[part]][[prop]][-1])\n",
    "      } else {\n",
    "        ft[[part]][[prop]] <- ft[[part]][[prop]][-1]\n",
    "      }\n",
    "      \n",
    "      if (is.vector(ft[[part]][[prop]])) {\n",
    "        names(ft[[part]][[prop]]) <- paste0(strata_,'||', names(ft[[part]][[prop]]))\n",
    "      } else if (is.data.frame(ft[[part]][[prop]])) {\n",
    "        colnames(ft[[part]][[prop]]) <- paste0(strata_,'||', colnames(ft[[part]][[prop]]))\n",
    "      }\n",
    "    }\n",
    "    ft[[part]]$spans$columns<-ft[[part]]$spans$columns[,-1]\n",
    "    ft[[part]]$spans$rows<-ft[[part]]$spans$rows[,-1]\n",
    "    ft[[part]]$content$data <- ft[[part]]$content$data[, -1]\n",
    "    ft[[part]]$content$ncol <- ft[[part]]$content$ncol -1\n",
    "    ft[[part]]$content$keys <- paste0(strata_,'||',ft[[part]]$content$keys[ -1])\n",
    "    colnames(ft[[part]]$content$data) <- paste0(strata_,'||',colnames(ft[[part]]$content$data))\n",
    "\n",
    "    for (prop_lvl_1 in names(ft[[part]]$styles)){\n",
    "      for (prop_lvl_2 in names(ft[[part]]$styles[[prop_lvl_1]])){\n",
    "        ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['data']] <- \n",
    "          ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['data']][,-1] \n",
    "        ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['keys']] <-  \n",
    "          paste0(strata_,'||',ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['keys']][-1])\n",
    "        ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['ncol']] <- \n",
    "          ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['ncol']] -1\n",
    "        colnames(ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$data) <- \n",
    "          paste0(strata_,'||',colnames(ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$data))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(ft)\n",
    "}\n",
    "\n",
    "# Concatenate ft1 and ft2\n",
    "# ft_c <- ft1\n",
    "ft_c_others <- function(ft_c,ft,strata_){\n",
    "  ft <- ft_c_other(ft,strata_)\n",
    "  ft_c$col_keys <- c(ft_c$col_keys, ft$col_keys)\n",
    "\n",
    "  for (part in c(\"header\", \"body\", \"footer\")) {\n",
    "    for (prop in c(\"dataset\", \"col_keys\", \"colwidth\", \"colwidths\")) {\n",
    "        if (is.vector(ft_c[[part]][[prop]])) {\n",
    "          ft_c[[part]][[prop]] <- c(ft_c[[part]][[prop]], ft[[part]][[prop]])\n",
    "        } else if (is.matrix(ft_c[[part]][[prop]]) || is.data.frame(ft_c[[part]][[prop]])) {\n",
    "          ft_c[[part]][[prop]] <- cbind(ft_c[[part]][[prop]], ft[[part]][[prop]])\n",
    "        }\n",
    "      }\n",
    "      ft_c[[part]]$content$data <- cbind(ft_c[[part]]$content$data, ft[[part]]$content$data)\n",
    "      ft_c[[part]]$content$keys <- c(ft_c[[part]]$content$keys, ft[[part]]$content$keys)\n",
    "      ft_c[[part]]$content$ncol <- ft_c[[part]]$content$ncol + ft[[part]]$content$ncol\n",
    "      ft_c[[part]]$spans$columns<- cbind(ft_c[[part]]$spans$columns,ft[[part]]$spans$columns)\n",
    "      ft_c[[part]]$spans$rows   <- cbind(ft_c[[part]]$spans$rows,ft[[part]]$spans$rows)\n",
    "      # print(colnames(ft_c[[part]]$content$data))\n",
    "      # print(colnames(ft[[part]]$content$data))\n",
    "      # colnames(ft_c[[part]]$content$data) <- c(colnames(ft_c[[part]]$content$data), colnames(ft[[part]]$content$data)) \n",
    "      \n",
    "    \n",
    "    for (prop_lvl_1 in names(ft_c[[part]]$styles)){\n",
    "      for (prop_lvl_2 in names(ft_c[[part]]$styles[[prop_lvl_1]])){\n",
    "        ft_c[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['data']] <- \n",
    "          cbind(ft_c[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$data,ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$data)\n",
    "        ft_c[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['keys']] <- \n",
    "          c(ft_c[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$keys,ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$keys)\n",
    "        ft_c[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]][['ncol']] <- \n",
    "          ft_c[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$ncol + ft[[part]]$styles[[prop_lvl_1]][[prop_lvl_2]]$ncol\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(ft_c)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"\u001b[1m\u001b[22mOne or more parsing issues, call `problems()` on your data frame for details,\n",
      "e.g.:\n",
      "  dat <- vroom(...)\n",
      "  problems(dat)\"\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m102505\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m272\u001b[39m\n",
      "\u001b[36m--\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m--------------------------------------------------------\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m   (1): SURGMONTH\n",
      "\u001b[32mdbl\u001b[39m (270): PATIENTID, RUCA1, RUCA2, ADI_NATRANK_MEDIAN, PROC_SURVIVALDAYS, D...\n",
      "\u001b[33mlgl\u001b[39m   (1): BALLDIA_NOSTENT_2\n",
      "\n",
      "\u001b[36mi\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mi\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"LOADED: CAS_International_PROC_20230801.csv  to  d_original  n= 102505\"\n",
      "[1] \"df created: d_proc\"\n",
      "[1] \"loaded: d_proc\"\n",
      "[1] \"CREATED: p_tiastk_f  with forumla    as.factor(  df$p_tiastk)\"\n",
      "[1] \"CREATED: p_tianone_f  with forumla    as.factor(  df$p_tianone)\"\n",
      "[1] \"CREATED: p_tiarret_f  with forumla    as.factor(  df$p_tiarret)\"\n",
      "[1] \"CREATED: p_tialret_f  with forumla    as.factor(  df$p_tialret)\"\n",
      "[1] \"CREATED: p_tiarcort_f  with forumla    as.factor(  df$p_tiarcort)\"\n",
      "[1] \"CREATED: p_tialcort_f  with forumla    as.factor(  df$p_tialcort)\"\n",
      "[1] \"CREATED: p_tiavb_f  with forumla    as.factor(  df$p_tiavb)\"\n",
      "[1] \"CREATED: p_stknone_f  with forumla    as.factor(  df$p_stknone)\"\n",
      "[1] \"CREATED: p_stkrret_f  with forumla    as.factor(  df$p_stkrret)\"\n",
      "[1] \"CREATED: p_stklret_f  with forumla    as.factor(  df$p_stklret)\"\n",
      "[1] \"CREATED: p_stkrcort_f  with forumla    as.factor(  df$p_stkrcort)\"\n",
      "[1] \"CREATED: p_stklcort_f  with forumla    as.factor(  df$p_stklcort)\"\n",
      "[1] \"CREATED: p_stkvb_f  with forumla    as.factor(  df$p_stkvb)\"\n",
      "[1] \"CREATED: side_f  with forumla    as.factor(  df$side)\"\n",
      "[1] \"CREATED: evt_r  with forumla  ifelse(rowSums(select(df, c(  p_tiarret,  p_tiarcort,  p_stkrret,  p_stkrcort))>0),1,0)\"\n",
      "[1] \"CREATED: evt_l  with forumla  ifelse(rowSums(select(df, c(  p_tialret,  p_tialcort,  p_stklret,  p_stklcort))>0),1,0)\"\n",
      "[1] \"CREATED: evt_r2  with forumla  as.integer(Reduce('|',select(df, c(  p_tiarret,  p_tiarcort,  p_stkrret,  p_stkrcort))))\"\n",
      "[1] \"CREATED: evt_l2  with forumla  as.integer(Reduce('|',select(df, c(  p_tialret,  p_tialcort,  p_stklret,  p_stklcort))))\"\n",
      "[1] \"CREATED: evt_r_days  with forumla  pmin(  df$p_tiarret_d,  df$p_tiarcort_d,  df$p_stkrret_d,  df$p_stkrcort_d,na.rm=TRUE)\"\n",
      "[1] \"CREATED: evt_l_days  with forumla  pmin(  df$p_tialret_d,  df$p_tialcort_d,  df$p_stklret_d,  df$p_stklcort_d,na.rm=TRUE)\"\n",
      "[1] \"CREATED: evt_days0  with forumla  pmin(  df$evt_r_days,  df$evt_l_days,na.rm=TRUE)\"\n",
      "[1] \"CREATED: evt_same  with forumla  ifelse((  df$side==1 &   df$evt_r==1) | (  df$side==2 &   df$evt_l==1),1,0)\"\n",
      "[1] \"CREATED: evt_days  with forumla  ifelse(  df$side==1,  df$evt_r_days,ifelse(  df$side==2,  df$evt_l_days,NA))\"\n",
      "[1] \"CREATED: evt_days_c  with forumla  as.character(  df$evt_days)\"\n",
      "[1] \"CREATED: evt_days2w  with forumla  ifelse(  df$evt_days>-14,  df$evt_days,NA)\"\n",
      "[1] \"CREATED: evt_days00  with forumla  ifelse(  df$evt_days>0,  df$evt_days,NA)\"\n",
      "[1] \"CREATED: evt_days_r  with forumla    df$evt_days * -1\"\n",
      "[1] \"CREATED: evt_days1w  with forumla  ifelse(  df$evt_days>-7,  df$evt_days,NA)\"\n",
      "[1] \"CREATED: race3  with forumla  ifelse(  df$race==5,1,ifelse(  df$race==3,2,3))\"\n",
      "[1] \"CREATED: sex10  with forumla  ifelse(  df$sex==1,1,0)\"\n",
      "[1] \"CREATED: dm10  with forumla  ifelse(  df$copd>0,1,0)\"\n",
      "[1] \"CREATED: htn10  with forumla  ifelse(  df$htn>0,1,0)\"\n",
      "[1] \"CREATED: smok3  with forumla  ifelse(  df$smok==0,3,  df$smok)\"\n",
      "[1] \"CREATED: etiology  with forumla    as.factor(  df$side)\"\n",
      "[1] \"CREATED: etiology_l  with forumla    as.factor(  df$side)\"\n",
      "[1] \"CREATED: dysrhythmia_  with forumla  ifelse(is.na(  df$dysrhythmia),99,  df$dysrhythmia)\"\n",
      "[1] \"CREATED: afib_  with forumla  ifelse(  df$dysrhythmia_==1,1,0)\"\n",
      "[1] \"CREATED: afib  with forumla    as.factor(  df$afib_)\"\n",
      "[1] \"CREATED: bmi  with forumla    df$wt_kg/(  df$ht_cm/100)^2\"\n",
      "[1] \"CREATED: evt_r_sev  with forumla  ifelse(  df$p_stkrcort==1,1,ifelse(  df$p_tiarcort==1,2,ifelse((  df$p_stkrret==1)|(  df$p_tiarret==1),3,0)))\"\n",
      "[1] \"CREATED: evt_l_sev  with forumla  ifelse(  df$p_stklcort==1,1,ifelse(  df$p_tialcort==1,2,ifelse((  df$p_stklret==1)|(  df$p_tialret==1),3,0)))\"\n",
      "[1] \"CREATED: p_tiarret_d_  with forumla    df$p_tiarret_d\"\n",
      "[1] \"CREATED: p_tialret_d_  with forumla    df$p_tialret_d\"\n",
      "[1] \"CREATED: p_tiarcort_d_  with forumla    df$p_tiarcort_d\"\n",
      "[1] \"CREATED: p_tialcort_d_  with forumla    df$p_tialcort_d\"\n",
      "[1] \"CREATED: p_tiavb_d_  with forumla    df$p_tiavb_d\"\n",
      "[1] \"CREATED: p_tia_d_  with forumla    df$p_tia_d\"\n",
      "[1] \"CREATED: p_stkrret_d_  with forumla    df$p_stkrret_d\"\n",
      "[1] \"CREATED: p_stklret_d_  with forumla    df$p_stklret_d\"\n",
      "[1] \"CREATED: p_stkrcort_d_  with forumla    df$p_stkrcort_d\"\n",
      "[1] \"CREATED: p_stklcort_d_  with forumla    df$p_stklcort_d\"\n",
      "[1] \"CREATED: p_stkvb_d_  with forumla    df$p_stkvb_d\"\n",
      "[1] \"CREATED: p_stk_d_  with forumla    df$p_stk_d\"\n",
      "[1] \"CREATED: p_tiarret_d_9999  with forumla  ifelse(is.na(  df$p_tiarret_d)|  df$p_tiarret_d>0,9999,  df$p_tiarret_d*-1)\"\n",
      "[1] \"CREATED: p_tiarcort_d_9999  with forumla  ifelse(is.na(  df$p_tiarcort_d)|  df$p_tiarcort_d>0,9999,  df$p_tiarcort_d*-1)\"\n",
      "[1] \"CREATED: p_stkrret_d_9999  with forumla  ifelse(is.na(  df$p_stkrret_d)|  df$p_stkrret_d>0,9999,  df$p_stkrret_d*-1)\"\n",
      "[1] \"CREATED: p_stkrcort_d_9999  with forumla  ifelse(is.na(  df$p_stkrcort_d)|  df$p_stkrcort_d>0,9999,  df$p_stkrcort_d*-1)\"\n",
      "[1] \"CREATED: p_tialret_d_9999  with forumla  ifelse(is.na(  df$p_tialret_d)|  df$p_tialret_d>0,9999,  df$p_tialret_d*-1)\"\n",
      "[1] \"CREATED: p_tialcort_d_9999  with forumla  ifelse(is.na(  df$p_tialcort_d)|  df$p_tialcort_d>0,9999,  df$p_tialcort_d*-1)\"\n",
      "[1] \"CREATED: p_stklret_d_9999  with forumla  ifelse(is.na(  df$p_stklret_d)|  df$p_stklret_d>0,9999,  df$p_stklret_d*-1)\"\n",
      "[1] \"CREATED: p_stklcort_d_9999  with forumla  ifelse(is.na(  df$p_stklcort_d)|  df$p_stklcort_d>0,9999,  df$p_stklcort_d*-1)\"\n",
      "[1] \"CREATED: min_right  with forumla  pmin(  df$p_tiarret_d_9999,  df$p_tiarcort_d_9999,  df$p_stkrret_d_9999,  df$p_stkrcort_d_9999)\"\n",
      "[1] \"CREATED: min_left  with forumla  pmin(  df$p_tialret_d_9999,  df$p_tialcort_d_9999,  df$p_stklret_d_9999,  df$p_stklcort_d_9999)\"\n",
      "[1] \"CREATED: which_right_min_  with forumla  ifelse(  df$min_right==  df$p_stkrcort_d_9999,1,ifelse(  df$min_right==  df$p_tiarcort_d_9999,2,ifelse(  df$min_right==  df$p_stkrret_d_9999,3,ifelse(  df$min_right==  df$p_tiarret_d_9999,4,5))))\"\n",
      "[1] \"CREATED: which_left_min_  with forumla  ifelse(  df$min_left==  df$p_stklcort_d_9999,1,ifelse(  df$min_left==  df$p_tialcort_d_9999,2,ifelse(  df$min_left==  df$p_stklret_d_9999,3,ifelse(  df$min_left==  df$p_tialret_d_9999,4,5))))\"\n",
      "[1] \"CREATED: evt_type_right__  with forumla  ifelse(  df$p_tiarret_d_9999==9999 &   df$p_tiarcort_d_9999==9999 &   df$p_stkrret_d_9999==9999 &   df$p_stkrcort_d_9999==9999,5,  df$which_right_min_)\"\n",
      "[1] \"CREATED: evt_type_left__  with forumla  ifelse(  df$p_tialret_d_9999==9999 &   df$p_tialcort_d_9999==9999 &   df$p_stklret_d_9999==9999 &   df$p_stklcort_d_9999==9999,5,  df$which_left_min_)\"\n",
      "[1] \"CREATED: evt_type_right_  with forumla  ifelse(  df$evt_type_right__==1,1,ifelse(  df$evt_type_right__==2,2,ifelse(  df$evt_type_right__<5,3,4)))\"\n",
      "[1] \"CREATED: evt_type_left_  with forumla  ifelse(  df$evt_type_left__==1,1,ifelse(  df$evt_type_left__==2,2,ifelse(  df$evt_type_left__<5,3,4)))\"\n",
      "[1] \"CREATED: last_event_type_  with forumla  ifelse(  df$side==1,  df$evt_type_right_,  df$evt_type_left_)\"\n",
      "[1] \"CREATED: last_event_type  with forumla    as.factor(  df$last_event_type_)\"\n",
      "[1] \"CREATED: sten_us  with forumla  ifelse(  df$side==1,  df$us_r,  df$us_l)\"\n",
      "[1] \"CREATED: sten_mra  with forumla  ifelse(  df$side==1,  df$sten_r_mra,  df$sten_l_mra)\"\n",
      "[1] \"CREATED: sten_cta  with forumla  ifelse(  df$side==1,  df$sten_r_cta,  df$sten_l_cta)\"\n",
      "[1] \"CREATED: sten_angio  with forumla  ifelse(  df$side==1,  df$sten_r_angio,  df$sten_l_angio)\"\n",
      "[1] \"CREATED: sten_any_  with forumla  ifelse(!is.na(  df$sten_angio),  df$sten_angio,ifelse(!is.na(   df$sten_cta),   df$sten_cta,ifelse(!is.na(  df$sten_mra),   df$sten_mra,  df$sten_us)))\"\n",
      "[1] \"CREATED: sten_any  with forumla  ifelse(!is.na(  df$sten_angio),  df$sten_angio,ifelse(!is.na(   df$sten_cta),   df$sten_cta,ifelse(!is.na(  df$sten_mra),   df$sten_mra,  df$sten_us)))\"\n",
      "[1] \"CREATED: sten_70  with forumla  ifelse(  df$sten_any_ >=3,1,0)\"\n",
      "[1] \"CREATED: sten_3  with forumla  ifelse(  df$sten_any<3,1,ifelse(  df$sten_any<5,2,3))\"\n",
      "[1] \"CREATED: sten_3_r  with forumla  ifelse(  df$sten_any<3,1,ifelse(  df$sten_any<5,2,3))\"\n",
      "[1] \"CREATED: sten_filter  with forumla  ifelse(!is.na(  df$sten_any_) &  (  df$sten_any_==2 |   df$sten_any_==3),1,0)\"\n",
      "[1] \"CREATED: sten_2_  with forumla  ifelse(  df$sten_any_==3,1,2)\"\n",
      "[1] \"CREATED: sten_2  with forumla    as.factor(  df$sten_2_)\"\n",
      "[1] \"CREATED: evt_days_r_30  with forumla  ifelse((  df$evt_r_days>-30)&(  df$evt_r_days<1),  df$evt_r_days,NA)\"\n",
      "[1] \"CREATED: evt_days_l_30  with forumla  ifelse((  df$evt_l_days>-30)&(  df$evt_l_days<1),  df$evt_l_days,NA)\"\n",
      "[1] \"CREATED: evt_days_30  with forumla  ifelse((  df$side==1)&!is.na(  df$evt_days_r_30),  df$evt_days_r_30,ifelse((  df$side==2)&!is.na(  df$evt_days_l_30),  df$evt_days_l_30,NA))*-1\"\n",
      "[1] \"CREATED: evt_days_gp4  with forumla  ifelse(  df$evt_days_30<=1,1,ifelse(  df$evt_days_30<=7,2,ifelse(  df$evt_days_30<=14,3,4)))\"\n",
      "[1] \"CREATED: evt_days_gp4_for_r  with forumla    df$evt_days_gp4\"\n",
      "[1] \"CREATED: evt_l_stk_30  with forumla  ifelse((  df$p_stklcort_d>-30)&(  df$p_stklcort_d<1),  df$p_stklcort_d,NA)\"\n",
      "[1] \"CREATED: evt_r_stk_30  with forumla  ifelse((  df$p_stkrcort_d>-30)&(  df$p_stkrcort_d<1),  df$p_stkrcort_d,NA)\"\n",
      "[1] \"CREATED: evt_l_tia_30  with forumla  ifelse((  df$p_tialcort_d>-30)&(  df$p_tialcort_d<1),  df$p_tialcort_d,NA)\"\n",
      "[1] \"CREATED: evt_r_tia_30  with forumla  ifelse((  df$p_tiarcort_d-30)&(  df$p_tiarcort_d<1),  df$p_tiarcort_d,NA)\"\n",
      "[1] \"CREATED: evt_l_rettia_30  with forumla  ifelse((  df$p_tialcort_d>-30)&(  df$p_tialcort_d<1),  df$p_tialcort_d,NA)\"\n",
      "[1] \"CREATED: evt_r_rettia_30  with forumla  ifelse((  df$p_tiarcort_d>-30)&(  df$p_tiarcort_d<1),  df$p_tiarcort_d,NA)\"\n",
      "[1] \"CREATED: evt_l_retstk_30  with forumla  ifelse((  df$p_stklret_d>-30)&(  df$p_stklret_d<1),  df$p_stklret_d,NA)\"\n",
      "[1] \"CREATED: evt_r_retstk_30  with forumla  ifelse((  df$p_stkrret_d>-30)&(  df$p_stkrret_d<1),  df$p_stkrret_d,NA)\"\n",
      "[1] \"CREATED: evt_l_ret_30  with forumla  pmin(  df$evt_l_tia_30,  df$evt_l_rettia_30,na.rm=TRUE)\"\n",
      "[1] \"CREATED: evt_r_ret_30  with forumla  pmin(  df$evt_r_tia_30,  df$evt_r_rettia_30,na.rm=TRUE)\"\n",
      "[1] \"CREATED: evt_stk_30  with forumla  ifelse((  df$side==1)&!is.na(  df$evt_r_stk_30),  df$evt_r_stk_30,ifelse((  df$side==2)&!is.na(  df$evt_l_stk_30),  df$evt_l_stk_30,NA))*-1\"\n",
      "[1] \"CREATED: evt_tia_30  with forumla  ifelse((  df$side==1)&!is.na(  df$evt_r_tia_30),  df$evt_r_tia_30,ifelse((  df$side==2)&!is.na(  df$evt_l_tia_30),  df$evt_l_tia_30,NA))*-1\"\n",
      "[1] \"CREATED: evt_ret_30  with forumla  ifelse((  df$side==1)&!is.na(  df$evt_r_retstk_30),  df$evt_r_retstk_30,ifelse((  df$side==2)&!is.na(  df$evt_l_retstk_30),  df$evt_l_retstk_30,NA))*-1\"\n",
      "[1] \"CREATED: evt_ret_tia_30  with forumla  pmin(  df$evt_tia_30,  df$evt_ret_30,na.rm=TRUE)\"\n",
      "[1] \"CREATED: evt_stk_days_gp4  with forumla  ifelse(  df$evt_stk_30<=1,1,ifelse(  df$evt_stk_30<=7,2,ifelse(  df$evt_stk_30<=14,3,4)))\"\n",
      "[1] \"CREATED: evt_tia_days_gp4  with forumla  ifelse(  df$evt_tia_30<=1,1,ifelse(  df$evt_tia_30<=7,2,ifelse(  df$evt_tia_30<=14,3,4)))\"\n",
      "[1] \"CREATED: evt_ret_days_gp4  with forumla  ifelse(  df$evt_ret_30<=1,1,ifelse(  df$evt_ret_30<=7,2,ifelse(  df$evt_ret_30<=14,3,4)))\"\n",
      "[1] \"CREATED: evt_n  with forumla    as.numeric(  df$evt)\"\n",
      "[1] \"CREATED: evt_for_r  with forumla    as.numeric(  df$evt)\"\n",
      "[1] \"CREATED: evt_tia_  with forumla  ifelse(  df$evt_no_tia==1,0,1)\"\n",
      "[1] \"CREATED: evt_tia  with forumla  ifelse(  df$evt_no_tia==1,0,1)\"\n",
      "[1] \"CREATED: evt_tia_r  with forumla  ifelse(  df$evt_no_tia==1,0,1)\"\n",
      "[1] \"CREATED: evt_stk_  with forumla  ifelse(  df$evt_no_stk==1,0,1)\"\n",
      "[1] \"CREATED: evt_stk  with forumla  ifelse(  df$evt_no_stk==1,0,1)\"\n",
      "[1] \"CREATED: evt_stk_r  with forumla  ifelse(  df$evt_no_stk==1,0,1)\"\n",
      "[1] \"CREATED: evt_mi_  with forumla  ifelse(  df$comp_mi == 2,1,0)\"\n",
      "[1] \"CREATED: evt_mi  with forumla    df$evt_mi_\"\n",
      "[1] \"CREATED: evt_mi_r  with forumla    df$evt_mi_\"\n",
      "[1] \"CREATED: evt_stk_mi_  with forumla  ifelse(  df$evt_mi_==1 |   df$evt_n ==1,1,0)\"\n",
      "[1] \"CREATED: evt_stk_mi  with forumla    df$evt_stk_mi_\"\n",
      "[1] \"CREATED: evt_stk_mi_r  with forumla    df$evt_stk_mi_\"\n",
      "[1] \"CREATED: evt_stk_mi_death_  with forumla  ifelse(  df$dc_status ==4 |   df$evt_stk_mi_ ==1,1,0)\"\n",
      "[1] \"CREATED: evt_stk_mi_death  with forumla    df$evt_stk_mi_death_\"\n",
      "[1] \"CREATED: evt_stk_mi_death_r  with forumla    df$evt_stk_mi_death_\"\n",
      "[1] \"CREATED: evt_days_gp5  with forumla  ifelse(  df$evt_days_30<1,1,ifelse(  df$evt_days_30<2,2,ifelse(  df$evt_days_30<7,3,ifelse(  df$evt_days_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_days_gp5_for_r  with forumla    df$evt_days_gp5\"\n",
      "[1] \"CREATED: evt_days_gp4_test  with forumla  ifelse(  df$evt_days_30<=1,1,ifelse(  df$evt_days_30<=7,2,ifelse(  df$evt_days_30<=14,3,4)))\"\n",
      "[1] \"CREATED: evt_stk_gp5  with forumla  ifelse(  df$evt_stk_30<1,1,ifelse(  df$evt_stk_30<2,2,ifelse(  df$evt_stk_30<7,3,ifelse(  df$evt_stk_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_stk_gp5_for_r  with forumla  ifelse(  df$evt_stk_30<1,1,ifelse(  df$evt_stk_30<2,2,ifelse(  df$evt_stk_30<7,3,ifelse(  df$evt_stk_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_tia_gp5  with forumla  ifelse(  df$evt_tia_30<1,1,ifelse(  df$evt_tia_30<2,2,ifelse(  df$evt_tia_30<7,3,ifelse(  df$evt_tia_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_tia_gp5_for_r  with forumla  ifelse(  df$evt_tia_30<1,1,ifelse(  df$evt_tia_30<2,2,ifelse(  df$evt_tia_30<7,3,ifelse(  df$evt_tia_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_ret_gp5  with forumla  ifelse(  df$evt_ret_30<1,1,ifelse(  df$evt_ret_30<2,2,ifelse(  df$evt_ret_30<7,3,ifelse(  df$evt_ret_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_ret_gp5_for_r  with forumla  ifelse(  df$evt_ret_30<1,1,ifelse(  df$evt_ret_30<2,2,ifelse(  df$evt_ret_30<7,3,ifelse(  df$evt_ret_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_ret_tia_gp5  with forumla  ifelse(  df$evt_ret_tia_30<1,1,ifelse(  df$evt_ret_tia_30<2,2,ifelse(  df$evt_ret_tia_30<7,3,ifelse(  df$evt_ret_tia_30<14,4,5))))\"\n",
      "[1] \"CREATED: evt_ret_tia_gp5_for_r  with forumla  ifelse(  df$evt_ret_tia_30<1,1,ifelse(  df$evt_ret_tia_30<2,2,ifelse(  df$evt_ret_tia_30<7,3,ifelse(  df$evt_ret_tia_30<14,4,5))))\"\n",
      "[1] \"CREATED: mrs_dc  with forumla    as.factor(  df$mrs_dc_)\"\n",
      "[1] \"CREATED: mort_cause_dis  with forumla  ifelse(!is.na(  df$mort_cause) &    df$mort_cause==1,1,0)\"\n",
      "[1] \"CREATED: mort_cause_any  with forumla  ifelse(!is.na(  df$mort_cause),1,0)\"\n",
      "[1] \"CREATED: mort_cause_all_  with forumla  ifelse(!is.na(  df$mort_cause),  df$mort_cause,4)\"\n",
      "[1] \"CREATED: mort_cause_all  with forumla    as.factor(  df$mort_cause_all_)\"\n",
      "[1] \"CREATED: evt_no_stk_  with forumla  ifelse(is.na(  df$evt_no_stk),0,  df$evt_no_stk)\"\n",
      "[1] \"CREATED: evt_no_tia_  with forumla  ifelse(is.na(  df$evt_no_tia),0,  df$evt_no_tia)\"\n",
      "[1] \"CREATED: stk_death_tia_  with forumla  ifelse(  df$evt_no_tia_ == 0 |   df$evt_no_stk_ ==0 |   df$mort_cause_any == 1,1,0)\"\n",
      "[1] \"CREATED: stk_death_  with forumla  ifelse(   df$evt_no_stk_ ==0 |   df$mort_cause_any == 1,1,0)\"\n",
      "[1] \"CREATED: evt_days_gp_  with forumla  ifelse(  df$evt_days_30<=1,1,ifelse(  df$evt_days_30<7,2,ifelse(  df$evt_days_30<14,3,ifelse(  df$evt_days_30<30,4,NA))))\"\n",
      "[1] \"CREATED: evt_days_gp  with forumla    as.factor(  df$evt_days_gp_)\"\n",
      "[1] \"CREATED: stk_death_tia  with forumla    as.factor(  df$stk_death_tia_)\"\n",
      "[1] \"CREATED: stk_death  with forumla    as.factor(  df$stk_death_)\"\n",
      "[1] \"CREATED: stk_death_r  with forumla    as.factor(  df$stk_death_)\"\n",
      "[1] \"CREATED: evt_days_r_180  with forumla  ifelse((  df$evt_r_days>-180)&(  df$evt_r_days<1),  df$evt_r_days,NA)\"\n",
      "[1] \"CREATED: evt_days_l_180  with forumla  ifelse((  df$evt_l_days>-180)&(  df$evt_l_days<1),  df$evt_l_days,NA)\"\n",
      "[1] \"CREATED: evt_days_180  with forumla  ifelse((  df$side==1)&!is.na(  df$evt_days_r_180),  df$evt_days_r_180,ifelse((  df$side==2)&!is.na(  df$evt_days_l_180),  df$evt_days_l_180,NA))*-1\"\n",
      "[1] \"CREATED: evt_days_gp_180_  with forumla  ifelse(  df$evt_days_180<=1,1,ifelse(  df$evt_days_180<=7,2,ifelse(  df$evt_days_180<=14,3,ifelse(  df$evt_days_180<=30,4,ifelse(  df$evt_days_180<=180,5,NA)))))\"\n",
      "[1] \"CREATED: evt_days_gp_180  with forumla    as.factor(  df$evt_days_gp_180_)\"\n",
      "[1] \"CREATED: evt_days_gp_180_r  with forumla    as.factor(  df$evt_days_gp_180_)\"\n",
      "[1] \"CREATED: comp_mi_  with forumla  ifelse(is.na(  df$comp_mi__) | (  df$comp_mi__)==0,0,1)\"\n",
      "[1] \"CREATED: comp_mi  with forumla    as.factor(  df$comp_mi_)\"\n",
      "[1] \"CREATED: comp_bleed_  with forumla  ifelse(is.na(  df$comp_bleed__) | (  df$comp_bleed__)==0,0,1)\"\n",
      "[1] \"CREATED: comp_bleed  with forumla    as.factor(  df$comp_bleed_)\"\n",
      "[1] \"RECODE DONE: d_data\"\n",
      "[1] \"filtered: !is.na(evt_days_180) , n= 13871\"\n",
      "[1] \"filtered: sten_filter==1 , n= 5431\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error in 'add_p()/add_difference()' for variable 'mort_cause_all', p-value omitted:\n",
      "Error in stats::fisher.test(structure(c(4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, : FEXACT[f3xact()] error: hash key 5e+12 > INT_MAX, kyy=1915, it[i (= nco = 5)]= 1079115776.\n",
      "Rather set 'simulate.p.value=TRUE'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "shf <- read.csv(paste0(folder,'/recodeformulashortcuts.csv')) # short functions\n",
    "shf_1 <- shf[shf['type']==1,]\n",
    "shf_2 <- shf[shf['type']==2,]\n",
    "pattern0 <- str_c(\"\\\\b(?:\", shf_2[,'var'], \")[\\\\$\\\\#]\\\\w+\\\\b\", collapse = \"|\")\n",
    "pattern1 <- \"[\\\\$\\\\#]\\\\w+\\\\b\"\n",
    "pattern2 <- str_c(\"\\\\b\",shf_1[,'var'],\"\\\\b\",collapse = \"|\")\n",
    "patterns = c(pattern0, pattern1, pattern2)\n",
    "analysis <- read_excel(paste0(folder,'/recode.xlsx'),sheet = \"analysis\")\n",
    "analysis <- analysis |> filter(include!=0)\n",
    "report_name <- paste0(folder,\"/output/\",report_file())\n",
    "source_python(paste0(folder,\"/RecodeProcessing.py\"))\n",
    "\n",
    "doc <- read_docx()\n",
    "disp_ <- TRUE\n",
    "save_doc <- FALSE\n",
    "df<-NULL\n",
    "result<-NULL\n",
    "sub_pri<-NULL\n",
    "recode<-NULL\n",
    "original_sheet<-NULL\n",
    "recode_sheet<-NULL\n",
    "\n",
    "for (i in 1:nrow(analysis)){\n",
    "  switch(analysis[[i,'command']],\n",
    "    \"doc\"={\n",
    "      save_doc <- TRUE\n",
    "      doc<-recode_list(paste0(getwd(),\"/\",folder),doc) # NEW PYTHON CODE USE\n",
    "    },\n",
    "    \"load\"={\n",
    "      # processed_args<-get_args(analysis[i,],0,1,patterns)\n",
    "      assign(analysis[[i,'out']],load_file(analysis[[i,'in']]))\n",
    "      print(paste('LOADED:',analysis[[i,'in']],' to ',analysis[[i,'out']],' n=', nrow(get(analysis[[i,'out']]))))\n",
    "    },\n",
    "    \"ipynb_to_r\"={\n",
    "      input <- paste0(folder,\"/analysis.ipynb\")\n",
    "      convert_ipynb_to_r(input)\n",
    "    },\n",
    "    \"load_recode\"={\n",
    "      original_sheet <- read_excel(paste0(folder,'/recode.xlsx'), sheet = \"original\") \n",
    "      recode_sheet <-  read_excel(paste0(folder,'/recode.xlsx'), sheet = \"recode\")\n",
    "      recode <- load_recode(original_sheet, recode_sheet)\n",
    "    },\n",
    "    \"excel\"={\n",
    "      processed_args<-get_args(analysis[i,],0,1,patterns)\n",
    "      excel_file_name<-paste0(folder,'/output/',processed_args[[1]],'.xlsx')\n",
    "      write_xlsx(get(analysis[[i,'in']]), excel_file_name)\n",
    "      doc <- doc |> body_add_break() |> add_text(paste0('saved ',processed_args[[1]],'.xlsx'),level =2)   \n",
    "    },\n",
    "    \"rename\"={\n",
    "      processed_args<-get_args(analysis[i,],0,1,patterns)\n",
    "      assign(analysis[[i, 'out']], rename_variables(get(analysis[[i, 'in']]), recode, processed_args))\n",
    "      print(paste('df created:', analysis[[i, 'out']]))\n",
    "    },\n",
    "    \"formula\"={\n",
    "      recode<-fix_formulas(recode,patterns)\n",
    "    },\n",
    "    \"load_vars\"={\n",
    "      processed_args<-get_args(analysis[i,],0,1,patterns)\n",
    "      df_name <- analysis[[i, 'out']]\n",
    "      assign(df_name, reload_recode(get(analysis[[i, 'in']]),recode,processed_args))\n",
    "      print(paste('loaded:', df_name))\n",
    "    },\n",
    "    \"recode\"={\n",
    "      processed_args<-get_args(analysis[i,],0,1,patterns)\n",
    "      df_name <- analysis[[i, 'out']]\n",
    "      assign(df_name, reload_recode(get(analysis[[i, 'in']]),recode,processed_args))\n",
    "      suppressWarnings(assign(df_name,factorize_variables(df_name,recode)))\n",
    "      assign(df_name,relevel_variables(df_name,recode))\n",
    "      print(paste('RECODE DONE:', processed_args))\n",
    "    },\n",
    "    \"join\"={\n",
    "      processed_args<-get_args(analysis[i,],1,0,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      dfs <- strsplit(analysis[[i,'in']],\",\")[[1]] |> \n",
    "              lapply(str_trim)\n",
    "      assign(analysis[[i, 'out']], inner_join(get(dfs[[1]]), get(dfs[[2]]), by = ept(processed_args[[1]])))\n",
    "      print(paste('JOINED: ',analysis[[i,'in']], ' >>  ', analysis[[i,'out']]))\n",
    "    },\n",
    "    \"df\" = {\n",
    "      processed_args<-get_args(analysis[i,],0,1,patterns)\n",
    "      assign(analysis[[i,'out']],get(analysis[[i,'in']]))\n",
    "      doc <- add__n(analysis[[i,'out']],doc)\n",
    "    },\n",
    "    \"filter\" = {\n",
    "      processed_args<-get_args(analysis[i,],1,0,patterns,do_eval = FALSE,quote_var = FALSE)\n",
    "      assign(analysis[[i,'out']], refilter(analysis[[i,'in']],processed_args)) \n",
    "      doc <- add__n(analysis[[i,'out']],doc,paste(\"filter: \",get_title(analysis[i,]),processed_args[1]))\n",
    "    },\n",
    "    \"subset\" = {\n",
    "      processed_args<-get_args(analysis[i,],1,0,patterns,do_eval = TRUE,quote_var = TRUE)[[1]]\n",
    "      df_name_in <- analysis[[i,'in']]\n",
    "      df_name_out <- analysis[[i,'out']]\n",
    "      while  (nrow(analysis) > i && analysis[i,'cont']==1){\n",
    "        i<-i+1\n",
    "        processed_args<-c(processed_args,get_args(analysis[i,],1,0,patterns,do_eval = TRUE,quote_var = TRUE)[[1]])\n",
    "      }\n",
    "      assign(df_name_out, subset(df_name_in,processed_args)) \n",
    "      doc <- add__n(analysis[[i,'out']],doc,paste(\"subset: \",get_title(analysis[i,]),processed_args[1]))\n",
    "    },\n",
    "    \"ctn1\" = {doc<-ctn1_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"ctn2\" = {doc<-ctn2_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"ctn3\" = {doc<-ctn3_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"ctn4\" = {doc<-ctn4_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"summ\" = {doc<-summ_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"freq2\" = {doc<-freq2_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"freq1\" = {doc<-freq1_shell(recode,analysis[i,],1,1,patterns,doc)},\n",
    "    \"freq_list\" = {doc<-freq_list_shell(recode,analysis[i,],patterns,doc)},\n",
    "    \"glm\"= {doc<-gt_glm_shell(recode,analysis[i,],1,0,patterns,doc)},\n",
    "    \"tbl_summary\"= {\n",
    "      doc<-gt_tbl_summary_shell(recode,analysis[i,],1,0,patterns,doc)\n",
    "      },\n",
    "    \"aggregate_count\" = {\n",
    "      processed_args<-get_args(analysis[i,],1,1,patterns,do_eval = FALSE,quote_var = FALSE)\n",
    "      assign(analysis[[i,'out']],aggregate_count(analysis[[i,'in']],processed_args))\n",
    "    },\n",
    "    \"aggregate_props\" = {\n",
    "      processed_args<-get_args(analysis[i,],2,2,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      assign(analysis[[i,'out']],aggregate_props(analysis[[i,'in']],processed_args))\n",
    "    },\n",
    "    \"merge_props\" = {\n",
    "      processed_args<-get_args(analysis[i,],2,2,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      assign(analysis[[i,'out']],merge_props(analysis[[i,'in']],processed_args,report_name))\n",
    "      doc <- doc |> body_add_break() |> add_text(paste0('Merged data:',report_name,'.csv saved in reports folder '),level=9) \n",
    "    },\n",
    "    \"ggplot_bar\" = {\n",
    "      processed_args<-get_args(analysis[i,],2,1,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      bar_graph<-ggplot_bar(analysis[[i,'in']],processed_args)\n",
    "      doc <- doc |> body_add_break() |> add_text( get_title(analysis[i,])) |>  body_add_gg(bar_graph, width = 6, height = 4)\n",
    "    },\n",
    "    \"ggplot_bar_gp\" = {\n",
    "      processed_args<-get_args(analysis[i,],2,1,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      bar_graph<-ggplot_bar_gp(analysis[[i,'in']],processed_args)\n",
    "      doc <- doc |> body_add_break() |> add_text( get_title(analysis[i,])) |>  body_add_gg(bar_graph, width = 6, height = 4)\n",
    "    },\n",
    "    \"ggplot_hist\" = {\n",
    "      processed_args<-get_args(analysis[i,],1,1,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      plot<-ggplot_hist(analysis[[i,'in']],processed_args)\n",
    "      doc <- doc |> body_add_break() |>add_text( get_title(analysis[i,])) |>body_add_gg(plot, width = 6, height = 4)\n",
    "    },\n",
    "    \"ggplot_hist_l\" = {\n",
    "      processed_args<-get_args(analysis[i,],1,1,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "      doc<-ggplot_hist_l(analysis[[i,'in']],processed_args,doc,get_title(analysis[i,]))\n",
    "    },\n",
    "    \"title\"={doc <- doc |> body_add_break() |> add_text( get_title(analysis[i,]),level =1)}\n",
    ")\n",
    "}\n",
    "if (save_doc){\n",
    "  file_name <- paste0(report_name,\".docx\")\n",
    "  print(file_name)\n",
    "  doc<-print(doc, target = file_name)  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in undebug(gtsummary::tbl_summary):\n",
      "\"argument is not being debugged\"\n"
     ]
    }
   ],
   "source": [
    "# debug(generate_metadata)\n",
    "# debug(.formula_list_to_named_list)\n",
    "# debug(modify_table_styling)\n",
    "# undebug(modify_table_styling)\n",
    "# undebug(.formula_list_to_named_list)\n",
    "# undebug(generate_metadata)\n",
    "# undebug(gtsummary::tbl_summary)\n",
    "# undebug_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Occluded   70-99%    0-69% \n",
       "    3850     9698        0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(d_$sten_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  var1 var2 var3 var4 new_var\n",
      "1   10    5   15   20       2\n",
      "2   20   25   10   30       3\n",
      "3   30   35   25    5       4\n",
      "4   40   45   50 9999       1\n",
      "5 9999 9999 9999 9999       5\n"
     ]
    }
   ],
   "source": [
    "# Sample data frame\n",
    "df <- data.frame(\n",
    "  var1 = c(10, 20, 30, 40, 9999),\n",
    "  var2 = c(5, 25, 35, 45, 9999),\n",
    "  var3 = c(15, 10, 25, 50, 9999),\n",
    "  var4 = c(20, 30, 5, 9999, 9999)\n",
    ")\n",
    "\n",
    "create_min_var <- function(df, var1, var2, var3, var4) {\n",
    "  # Use pmin to get the minimum value among the variables\n",
    "  min_values <- pmin(df[[var1]], df[[var2]], df[[var3]], df[[var4]], na.rm = TRUE)\n",
    "  \n",
    "  # Create a new variable with values 1 to 4 depending on which variable has the lowest value\n",
    "  new_var <- ifelse(min_values == df[[var1]], 1,\n",
    "                    ifelse(min_values == df[[var2]], 2,\n",
    "                           ifelse(min_values == df[[var3]], 3,\n",
    "                                  ifelse(min_values == df[[var4]], 4, NA))))\n",
    "  \n",
    "  # Assign the value 5 if all variables have the value 9999\n",
    "  new_var <- ifelse(df[[var1]] == 9999 & df[[var2]] == 9999 & df[[var3]] == 9999 & df[[var4]] == 9999, 5, new_var)\n",
    "  \n",
    "  # Add the new variable to the data frame\n",
    "  df$new_var <- new_var\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "# df <- data.frame(var1 = c(1, 9999, 3, 9999), var2 = c(2, 9999, 1, 9999), var3 = c(3, 9999, 2, 9999), var4 = c(4, 9999, 4, 9999))\n",
    "df <- create_min_var(df, \"var1\", \"var2\", \"var3\", \"var4\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 5  4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>var1</th><th scope=col>var2</th><th scope=col>var3</th><th scope=col>var4</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>  10</td><td>   5</td><td>  15</td><td>  20</td></tr>\n",
       "\t<tr><td>  20</td><td>  25</td><td>  10</td><td>  30</td></tr>\n",
       "\t<tr><td>  30</td><td>  35</td><td>  25</td><td>   5</td></tr>\n",
       "\t<tr><td>  40</td><td>  45</td><td>  50</td><td>9999</td></tr>\n",
       "\t<tr><td>9999</td><td>9999</td><td>9999</td><td>9999</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 5  4 of type dbl\n",
       "\\begin{tabular}{llll}\n",
       " var1 & var2 & var3 & var4\\\\\n",
       "\\hline\n",
       "\t   10 &    5 &   15 &   20\\\\\n",
       "\t   20 &   25 &   10 &   30\\\\\n",
       "\t   30 &   35 &   25 &    5\\\\\n",
       "\t   40 &   45 &   50 & 9999\\\\\n",
       "\t 9999 & 9999 & 9999 & 9999\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 5  4 of type dbl\n",
       "\n",
       "| var1 | var2 | var3 | var4 |\n",
       "|---|---|---|---|\n",
       "|   10 |    5 |   15 |   20 |\n",
       "|   20 |   25 |   10 |   30 |\n",
       "|   30 |   35 |   25 |    5 |\n",
       "|   40 |   45 |   50 | 9999 |\n",
       "| 9999 | 9999 | 9999 | 9999 |\n",
       "\n"
      ],
      "text/plain": [
       "     var1 var2 var3 var4\n",
       "[1,]   10    5   15   20\n",
       "[2,]   20   25   10   30\n",
       "[3,]   30   35   25    5\n",
       "[4,]   40   45   50 9999\n",
       "[5,] 9999 9999 9999 9999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " as.matrix(df[c(\"var1\", \"var2\", \"var3\", \"var4\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "###\n",
    "USEFUL STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# to change content of a tbl_summary table \n",
    "gt$body$content$content$data[1,1]$label[1,1]<-'testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ft$body[[8]]$text$color$data[1,1]<-'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'color'</li><li>'font.size'</li><li>'bold'</li><li>'italic'</li><li>'underlined'</li><li>'font.family'</li><li>'hansi.family'</li><li>'eastasia.family'</li><li>'cs.family'</li><li>'vertical.align'</li><li>'shading.color'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'color'\n",
       "\\item 'font.size'\n",
       "\\item 'bold'\n",
       "\\item 'italic'\n",
       "\\item 'underlined'\n",
       "\\item 'font.family'\n",
       "\\item 'hansi.family'\n",
       "\\item 'eastasia.family'\n",
       "\\item 'cs.family'\n",
       "\\item 'vertical.align'\n",
       "\\item 'shading.color'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'color'\n",
       "2. 'font.size'\n",
       "3. 'bold'\n",
       "4. 'italic'\n",
       "5. 'underlined'\n",
       "6. 'font.family'\n",
       "7. 'hansi.family'\n",
       "8. 'eastasia.family'\n",
       "9. 'cs.family'\n",
       "10. 'vertical.align'\n",
       "11. 'shading.color'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"color\"           \"font.size\"       \"bold\"            \"italic\"         \n",
       " [5] \"underlined\"      \"font.family\"     \"hansi.family\"    \"eastasia.family\"\n",
       " [9] \"cs.family\"       \"vertical.align\"  \"shading.color\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(gt$body[[8]]$text)\n",
    "#'color''font.size''bold''italic''underlined''font.family''hansi.family''eastasia.family''cs.family''vertical.align''shading.color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"0-7 days\"\n"
     ]
    }
   ],
   "source": [
    "  # for (strata_ in levels_) {\n",
    "  #   # ft <- gt_tbl_summary(df[[strata_]], vars_list, by_var, categorical, continuous,summary_type_continuous,title)\n",
    "  #   print(strata_)\n",
    "  # }\n",
    "  strata_ <- levels_[[1]]\n",
    "  print(strata_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"dim.flextable FS_ 272\"\n",
      "[1] 15.77872\n",
      "[1] 15.77872\n",
      "[1] \"information_data_cell FS 378\"\n",
      "[1] \"wml_rows FS 212\"\n"
     ]
    }
   ],
   "source": [
    "# # debug(body_add_flextable)\n",
    "# # debug(gen_raw_wml)\n",
    "# debug(wml_rows)\n",
    "# debug(information_data_cell)\n",
    "# debug(table_width)\n",
    "# # debug(cell_struct_to_df)\n",
    "# debug(fortify_span)\n",
    "# debug(fortify_width)\n",
    "# debug(cell_struct_to_df)\n",
    "# debug(copy_border_bottom_to_next_border_top)\n",
    "doc <- read_docx()\n",
    "doc <- body_add_flextable(doc, ft_c)\n",
    "# undebug(copy_border_bottom_to_next_border_top)\n",
    "# undebug(table_width)\n",
    "# undebug(fortify_width)\n",
    "# undebug(cell_struct_to_df)\n",
    "# undebug(fortify_span)\n",
    "# undebug(gen_raw_wml)\n",
    "# undebug(wml_rows)\n",
    "# undebug(information_data_cell)\n",
    "# undebug(cell_struct_to_df)\n",
    "# undebug(body_add_flextable)\n",
    "doc<-print(doc, target = \"crest_analysis/output/testing.docx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "15"
      ],
      "text/latex": [
       "15"
      ],
      "text/markdown": [
       "15"
      ],
      "text/plain": [
       "[1] 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "debug(body_add_gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'data'</li><li>'layers'</li><li>'scales'</li><li>'guides'</li><li>'mapping'</li><li>'theme'</li><li>'coordinates'</li><li>'facet'</li><li>'plot_env'</li><li>'layout'</li><li>'labels'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'data'\n",
       "\\item 'layers'\n",
       "\\item 'scales'\n",
       "\\item 'guides'\n",
       "\\item 'mapping'\n",
       "\\item 'theme'\n",
       "\\item 'coordinates'\n",
       "\\item 'facet'\n",
       "\\item 'plot\\_env'\n",
       "\\item 'layout'\n",
       "\\item 'labels'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'data'\n",
       "2. 'layers'\n",
       "3. 'scales'\n",
       "4. 'guides'\n",
       "5. 'mapping'\n",
       "6. 'theme'\n",
       "7. 'coordinates'\n",
       "8. 'facet'\n",
       "9. 'plot_env'\n",
       "10. 'layout'\n",
       "11. 'labels'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"data\"        \"layers\"      \"scales\"      \"guides\"      \"mapping\"    \n",
       " [6] \"theme\"       \"coordinates\" \"facet\"       \"plot_env\"    \"layout\"     \n",
       "[11] \"labels\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'p_tiastk_f'</li><li>'p_tianone_f'</li><li>'p_tiarret_f'</li><li>'p_tialret_f'</li><li>'p_tiarcort_f'</li><li>'p_tialcort_f'</li><li>'p_tiavb_f'</li><li>'p_stknone_f'</li><li>'p_stkrret_f'</li><li>'p_stklret_f'</li><li>'p_stkrcort_f'</li><li>'p_stklcort_f'</li><li>'p_stkvb_f'</li><li>'side_f'</li><li>'evt_r'</li><li>'evt_l'</li><li>'evt_r2'</li><li>'evt_l2'</li><li>'evt_r_days'</li><li>'evt_l_days'</li><li>'evt_days0'</li><li>'evt_same'</li><li>'evt_days'</li><li>'evt_days_c'</li><li>'evt_days2w'</li><li>'evt_days00'</li><li>'evt_days_r'</li><li>'evt_days1w'</li><li>'race3'</li><li>'sex10'</li><li>'dm10'</li><li>'htn10'</li><li>'smok3'</li><li>'etiology'</li><li>'etiology_l'</li><li>'evt_r_sev'</li><li>'evt_l_sev'</li><li>'p_tiarret_d_'</li><li>'p_tialret_d_'</li><li>'p_tiarcort_d_'</li><li>'p_tialcort_d_'</li><li>'p_tiavb_d_'</li><li>'p_tia_d_'</li><li>'p_stkrret_d_'</li><li>'p_stklret_d_'</li><li>'p_stkrcort_d_'</li><li>'p_stklcort_d_'</li><li>'p_stkvb_d_'</li><li>'p_stk_d_'</li><li>'evt_days_r_30'</li><li>'evt_days_l_30'</li><li>'evt_days_30'</li><li>'evt_days_gp4'</li><li>'evt_days_gp4_for_r'</li><li>'evt_l_stk_30'</li><li>'evt_r_stk_30'</li><li>'evt_l_tia_30'</li><li>'evt_r_tia_30'</li><li>'evt_l_rettia_30'</li><li>'evt_r_rettia_30'</li><li>'evt_l_retstk_30'</li><li>'evt_r_retstk_30'</li><li>'evt_l_ret_30'</li><li>'evt_r_ret_30'</li><li>'evt_stk_30'</li><li>'evt_tia_30'</li><li>'evt_ret_30'</li><li>'evt_ret_tia_30'</li><li>'evt_stk_days_gp4'</li><li>'evt_tia_days_gp4'</li><li>'evt_ret_days_gp4'</li><li>'bmi'</li><li>'evt_n'</li><li>'evt_for_r'</li><li>'evt_tia_'</li><li>'evt_tia'</li><li>'evt_tia_r'</li><li>'evt_stk_'</li><li>'evt_stk'</li><li>'evt_stk_r'</li><li>'evt_mi_'</li><li>'evt_mi'</li><li>'evt_mi_r'</li><li>'evt_stk_mi_'</li><li>'evt_stk_mi'</li><li>'evt_stk_mi_r'</li><li>'evt_stk_mi_death_'</li><li>'evt_stk_mi_death'</li><li>'evt_stk_mi_death_r'</li><li>'evt_days_gp5'</li><li>'evt_days_gp5_for_r'</li><li>'evt_days_gp4_test'</li><li>'evt_stk_gp5'</li><li>'evt_stk_gp5_for_r'</li><li>'evt_tia_gp5'</li><li>'evt_tia_gp5_for_r'</li><li>'evt_ret_gp5'</li><li>'evt_ret_gp5_for_r'</li><li>'evt_ret_tia_gp5'</li><li>'evt_ret_tia_gp5_for_r'</li><li>'sten_us'</li><li>'sten_mra'</li><li>'sten_cta'</li><li>'sten_angio'</li><li>'sten_any'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'p\\_tiastk\\_f'\n",
       "\\item 'p\\_tianone\\_f'\n",
       "\\item 'p\\_tiarret\\_f'\n",
       "\\item 'p\\_tialret\\_f'\n",
       "\\item 'p\\_tiarcort\\_f'\n",
       "\\item 'p\\_tialcort\\_f'\n",
       "\\item 'p\\_tiavb\\_f'\n",
       "\\item 'p\\_stknone\\_f'\n",
       "\\item 'p\\_stkrret\\_f'\n",
       "\\item 'p\\_stklret\\_f'\n",
       "\\item 'p\\_stkrcort\\_f'\n",
       "\\item 'p\\_stklcort\\_f'\n",
       "\\item 'p\\_stkvb\\_f'\n",
       "\\item 'side\\_f'\n",
       "\\item 'evt\\_r'\n",
       "\\item 'evt\\_l'\n",
       "\\item 'evt\\_r2'\n",
       "\\item 'evt\\_l2'\n",
       "\\item 'evt\\_r\\_days'\n",
       "\\item 'evt\\_l\\_days'\n",
       "\\item 'evt\\_days0'\n",
       "\\item 'evt\\_same'\n",
       "\\item 'evt\\_days'\n",
       "\\item 'evt\\_days\\_c'\n",
       "\\item 'evt\\_days2w'\n",
       "\\item 'evt\\_days00'\n",
       "\\item 'evt\\_days\\_r'\n",
       "\\item 'evt\\_days1w'\n",
       "\\item 'race3'\n",
       "\\item 'sex10'\n",
       "\\item 'dm10'\n",
       "\\item 'htn10'\n",
       "\\item 'smok3'\n",
       "\\item 'etiology'\n",
       "\\item 'etiology\\_l'\n",
       "\\item 'evt\\_r\\_sev'\n",
       "\\item 'evt\\_l\\_sev'\n",
       "\\item 'p\\_tiarret\\_d\\_'\n",
       "\\item 'p\\_tialret\\_d\\_'\n",
       "\\item 'p\\_tiarcort\\_d\\_'\n",
       "\\item 'p\\_tialcort\\_d\\_'\n",
       "\\item 'p\\_tiavb\\_d\\_'\n",
       "\\item 'p\\_tia\\_d\\_'\n",
       "\\item 'p\\_stkrret\\_d\\_'\n",
       "\\item 'p\\_stklret\\_d\\_'\n",
       "\\item 'p\\_stkrcort\\_d\\_'\n",
       "\\item 'p\\_stklcort\\_d\\_'\n",
       "\\item 'p\\_stkvb\\_d\\_'\n",
       "\\item 'p\\_stk\\_d\\_'\n",
       "\\item 'evt\\_days\\_r\\_30'\n",
       "\\item 'evt\\_days\\_l\\_30'\n",
       "\\item 'evt\\_days\\_30'\n",
       "\\item 'evt\\_days\\_gp4'\n",
       "\\item 'evt\\_days\\_gp4\\_for\\_r'\n",
       "\\item 'evt\\_l\\_stk\\_30'\n",
       "\\item 'evt\\_r\\_stk\\_30'\n",
       "\\item 'evt\\_l\\_tia\\_30'\n",
       "\\item 'evt\\_r\\_tia\\_30'\n",
       "\\item 'evt\\_l\\_rettia\\_30'\n",
       "\\item 'evt\\_r\\_rettia\\_30'\n",
       "\\item 'evt\\_l\\_retstk\\_30'\n",
       "\\item 'evt\\_r\\_retstk\\_30'\n",
       "\\item 'evt\\_l\\_ret\\_30'\n",
       "\\item 'evt\\_r\\_ret\\_30'\n",
       "\\item 'evt\\_stk\\_30'\n",
       "\\item 'evt\\_tia\\_30'\n",
       "\\item 'evt\\_ret\\_30'\n",
       "\\item 'evt\\_ret\\_tia\\_30'\n",
       "\\item 'evt\\_stk\\_days\\_gp4'\n",
       "\\item 'evt\\_tia\\_days\\_gp4'\n",
       "\\item 'evt\\_ret\\_days\\_gp4'\n",
       "\\item 'bmi'\n",
       "\\item 'evt\\_n'\n",
       "\\item 'evt\\_for\\_r'\n",
       "\\item 'evt\\_tia\\_'\n",
       "\\item 'evt\\_tia'\n",
       "\\item 'evt\\_tia\\_r'\n",
       "\\item 'evt\\_stk\\_'\n",
       "\\item 'evt\\_stk'\n",
       "\\item 'evt\\_stk\\_r'\n",
       "\\item 'evt\\_mi\\_'\n",
       "\\item 'evt\\_mi'\n",
       "\\item 'evt\\_mi\\_r'\n",
       "\\item 'evt\\_stk\\_mi\\_'\n",
       "\\item 'evt\\_stk\\_mi'\n",
       "\\item 'evt\\_stk\\_mi\\_r'\n",
       "\\item 'evt\\_stk\\_mi\\_death\\_'\n",
       "\\item 'evt\\_stk\\_mi\\_death'\n",
       "\\item 'evt\\_stk\\_mi\\_death\\_r'\n",
       "\\item 'evt\\_days\\_gp5'\n",
       "\\item 'evt\\_days\\_gp5\\_for\\_r'\n",
       "\\item 'evt\\_days\\_gp4\\_test'\n",
       "\\item 'evt\\_stk\\_gp5'\n",
       "\\item 'evt\\_stk\\_gp5\\_for\\_r'\n",
       "\\item 'evt\\_tia\\_gp5'\n",
       "\\item 'evt\\_tia\\_gp5\\_for\\_r'\n",
       "\\item 'evt\\_ret\\_gp5'\n",
       "\\item 'evt\\_ret\\_gp5\\_for\\_r'\n",
       "\\item 'evt\\_ret\\_tia\\_gp5'\n",
       "\\item 'evt\\_ret\\_tia\\_gp5\\_for\\_r'\n",
       "\\item 'sten\\_us'\n",
       "\\item 'sten\\_mra'\n",
       "\\item 'sten\\_cta'\n",
       "\\item 'sten\\_angio'\n",
       "\\item 'sten\\_any'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'p_tiastk_f'\n",
       "2. 'p_tianone_f'\n",
       "3. 'p_tiarret_f'\n",
       "4. 'p_tialret_f'\n",
       "5. 'p_tiarcort_f'\n",
       "6. 'p_tialcort_f'\n",
       "7. 'p_tiavb_f'\n",
       "8. 'p_stknone_f'\n",
       "9. 'p_stkrret_f'\n",
       "10. 'p_stklret_f'\n",
       "11. 'p_stkrcort_f'\n",
       "12. 'p_stklcort_f'\n",
       "13. 'p_stkvb_f'\n",
       "14. 'side_f'\n",
       "15. 'evt_r'\n",
       "16. 'evt_l'\n",
       "17. 'evt_r2'\n",
       "18. 'evt_l2'\n",
       "19. 'evt_r_days'\n",
       "20. 'evt_l_days'\n",
       "21. 'evt_days0'\n",
       "22. 'evt_same'\n",
       "23. 'evt_days'\n",
       "24. 'evt_days_c'\n",
       "25. 'evt_days2w'\n",
       "26. 'evt_days00'\n",
       "27. 'evt_days_r'\n",
       "28. 'evt_days1w'\n",
       "29. 'race3'\n",
       "30. 'sex10'\n",
       "31. 'dm10'\n",
       "32. 'htn10'\n",
       "33. 'smok3'\n",
       "34. 'etiology'\n",
       "35. 'etiology_l'\n",
       "36. 'evt_r_sev'\n",
       "37. 'evt_l_sev'\n",
       "38. 'p_tiarret_d_'\n",
       "39. 'p_tialret_d_'\n",
       "40. 'p_tiarcort_d_'\n",
       "41. 'p_tialcort_d_'\n",
       "42. 'p_tiavb_d_'\n",
       "43. 'p_tia_d_'\n",
       "44. 'p_stkrret_d_'\n",
       "45. 'p_stklret_d_'\n",
       "46. 'p_stkrcort_d_'\n",
       "47. 'p_stklcort_d_'\n",
       "48. 'p_stkvb_d_'\n",
       "49. 'p_stk_d_'\n",
       "50. 'evt_days_r_30'\n",
       "51. 'evt_days_l_30'\n",
       "52. 'evt_days_30'\n",
       "53. 'evt_days_gp4'\n",
       "54. 'evt_days_gp4_for_r'\n",
       "55. 'evt_l_stk_30'\n",
       "56. 'evt_r_stk_30'\n",
       "57. 'evt_l_tia_30'\n",
       "58. 'evt_r_tia_30'\n",
       "59. 'evt_l_rettia_30'\n",
       "60. 'evt_r_rettia_30'\n",
       "61. 'evt_l_retstk_30'\n",
       "62. 'evt_r_retstk_30'\n",
       "63. 'evt_l_ret_30'\n",
       "64. 'evt_r_ret_30'\n",
       "65. 'evt_stk_30'\n",
       "66. 'evt_tia_30'\n",
       "67. 'evt_ret_30'\n",
       "68. 'evt_ret_tia_30'\n",
       "69. 'evt_stk_days_gp4'\n",
       "70. 'evt_tia_days_gp4'\n",
       "71. 'evt_ret_days_gp4'\n",
       "72. 'bmi'\n",
       "73. 'evt_n'\n",
       "74. 'evt_for_r'\n",
       "75. 'evt_tia_'\n",
       "76. 'evt_tia'\n",
       "77. 'evt_tia_r'\n",
       "78. 'evt_stk_'\n",
       "79. 'evt_stk'\n",
       "80. 'evt_stk_r'\n",
       "81. 'evt_mi_'\n",
       "82. 'evt_mi'\n",
       "83. 'evt_mi_r'\n",
       "84. 'evt_stk_mi_'\n",
       "85. 'evt_stk_mi'\n",
       "86. 'evt_stk_mi_r'\n",
       "87. 'evt_stk_mi_death_'\n",
       "88. 'evt_stk_mi_death'\n",
       "89. 'evt_stk_mi_death_r'\n",
       "90. 'evt_days_gp5'\n",
       "91. 'evt_days_gp5_for_r'\n",
       "92. 'evt_days_gp4_test'\n",
       "93. 'evt_stk_gp5'\n",
       "94. 'evt_stk_gp5_for_r'\n",
       "95. 'evt_tia_gp5'\n",
       "96. 'evt_tia_gp5_for_r'\n",
       "97. 'evt_ret_gp5'\n",
       "98. 'evt_ret_gp5_for_r'\n",
       "99. 'evt_ret_tia_gp5'\n",
       "100. 'evt_ret_tia_gp5_for_r'\n",
       "101. 'sten_us'\n",
       "102. 'sten_mra'\n",
       "103. 'sten_cta'\n",
       "104. 'sten_angio'\n",
       "105. 'sten_any'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] \"p_tiastk_f\"            \"p_tianone_f\"           \"p_tiarret_f\"          \n",
       "  [4] \"p_tialret_f\"           \"p_tiarcort_f\"          \"p_tialcort_f\"         \n",
       "  [7] \"p_tiavb_f\"             \"p_stknone_f\"           \"p_stkrret_f\"          \n",
       " [10] \"p_stklret_f\"           \"p_stkrcort_f\"          \"p_stklcort_f\"         \n",
       " [13] \"p_stkvb_f\"             \"side_f\"                \"evt_r\"                \n",
       " [16] \"evt_l\"                 \"evt_r2\"                \"evt_l2\"               \n",
       " [19] \"evt_r_days\"            \"evt_l_days\"            \"evt_days0\"            \n",
       " [22] \"evt_same\"              \"evt_days\"              \"evt_days_c\"           \n",
       " [25] \"evt_days2w\"            \"evt_days00\"            \"evt_days_r\"           \n",
       " [28] \"evt_days1w\"            \"race3\"                 \"sex10\"                \n",
       " [31] \"dm10\"                  \"htn10\"                 \"smok3\"                \n",
       " [34] \"etiology\"              \"etiology_l\"            \"evt_r_sev\"            \n",
       " [37] \"evt_l_sev\"             \"p_tiarret_d_\"          \"p_tialret_d_\"         \n",
       " [40] \"p_tiarcort_d_\"         \"p_tialcort_d_\"         \"p_tiavb_d_\"           \n",
       " [43] \"p_tia_d_\"              \"p_stkrret_d_\"          \"p_stklret_d_\"         \n",
       " [46] \"p_stkrcort_d_\"         \"p_stklcort_d_\"         \"p_stkvb_d_\"           \n",
       " [49] \"p_stk_d_\"              \"evt_days_r_30\"         \"evt_days_l_30\"        \n",
       " [52] \"evt_days_30\"           \"evt_days_gp4\"          \"evt_days_gp4_for_r\"   \n",
       " [55] \"evt_l_stk_30\"          \"evt_r_stk_30\"          \"evt_l_tia_30\"         \n",
       " [58] \"evt_r_tia_30\"          \"evt_l_rettia_30\"       \"evt_r_rettia_30\"      \n",
       " [61] \"evt_l_retstk_30\"       \"evt_r_retstk_30\"       \"evt_l_ret_30\"         \n",
       " [64] \"evt_r_ret_30\"          \"evt_stk_30\"            \"evt_tia_30\"           \n",
       " [67] \"evt_ret_30\"            \"evt_ret_tia_30\"        \"evt_stk_days_gp4\"     \n",
       " [70] \"evt_tia_days_gp4\"      \"evt_ret_days_gp4\"      \"bmi\"                  \n",
       " [73] \"evt_n\"                 \"evt_for_r\"             \"evt_tia_\"             \n",
       " [76] \"evt_tia\"               \"evt_tia_r\"             \"evt_stk_\"             \n",
       " [79] \"evt_stk\"               \"evt_stk_r\"             \"evt_mi_\"              \n",
       " [82] \"evt_mi\"                \"evt_mi_r\"              \"evt_stk_mi_\"          \n",
       " [85] \"evt_stk_mi\"            \"evt_stk_mi_r\"          \"evt_stk_mi_death_\"    \n",
       " [88] \"evt_stk_mi_death\"      \"evt_stk_mi_death_r\"    \"evt_days_gp5\"         \n",
       " [91] \"evt_days_gp5_for_r\"    \"evt_days_gp4_test\"     \"evt_stk_gp5\"          \n",
       " [94] \"evt_stk_gp5_for_r\"     \"evt_tia_gp5\"           \"evt_tia_gp5_for_r\"    \n",
       " [97] \"evt_ret_gp5\"           \"evt_ret_gp5_for_r\"     \"evt_ret_tia_gp5\"      \n",
       "[100] \"evt_ret_tia_gp5_for_r\" \"sten_us\"               \"sten_mra\"             \n",
       "[103] \"sten_cta\"              \"sten_angio\"            \"sten_any\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(plot$data)[duplicated(names(plot$data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "i<-15\n",
    "analysis_row<-analysis[i,]\n",
    "processed_args<-get_args(analysis[i,],1,1,patterns,do_eval = FALSE,quote_var = TRUE)\n",
    "args<-processed_args\n",
    "# plot<-ggplot_hist(analysis[[i,'in']],processed_args)\n",
    "df_name <- 'df_merge'\n",
    "df<-get(df_name)\n",
    "x_var <-ept(args[[1]])\n",
    "\n",
    "\n",
    "histogram <- ggplot(df, aes(x = .data[[x_var]]))\n",
    "#  +\n",
    "# geom_histogram(binwidth = 0.5, fill = \"grey\", color = \"black\", alpha = 0.5) +  # Customize the histogram aesthetics\n",
    "# labs(x = \"Values\", y = \"Frequency\", title = \"Histogram of Values\") +  # Add labels and title\n",
    "# stat_bin(geom = \"text\", aes(label = ifelse(..count.. > 0, ..count.., \"\")), vjust = -0.5) +  # Add count labels on top of each bar\n",
    "# theme_minimal()  # Apply a theme (optional)\n",
    "plot<-histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'gp'</li><li>'evt_n'</li><li>'evt_tia'</li><li>'evt_stk'</li><li>'tb'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'gp'\n",
       "\\item 'evt\\_n'\n",
       "\\item 'evt\\_tia'\n",
       "\\item 'evt\\_stk'\n",
       "\\item 'tb'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'gp'\n",
       "2. 'evt_n'\n",
       "3. 'evt_tia'\n",
       "4. 'evt_stk'\n",
       "5. 'tb'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"gp\"      \"evt_n\"   \"evt_tia\" \"evt_stk\" \"tb\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(plot$data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'\"evt_n\"'"
      ],
      "text/latex": [
       "'\"evt\\_n\"'"
      ],
      "text/markdown": [
       "'\"evt_n\"'"
      ],
      "text/plain": [
       "[1] \"\\\"evt_n\\\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'which_right_min_' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'which_right_min_' not found\nTraceback:\n",
      "1. ifelse(df$p_tiarret_d_9999 == 9999 & df$p_tiarcort_d_9999 == \n .     9999 & df$p_stkrret_d_9999 == 9999 & df$p_stkrcort_d_9999 == \n .     9999, 5, which_right_min_)"
     ]
    }
   ],
   "source": [
    "df<-d_\n",
    "ifelse(  df$p_tiarret_d_9999==9999 &   df$p_tiarcort_d_9999==9999 &   df$p_stkrret_d_9999==9999 &   df$p_stkrcort_d_9999==9999,5,which_right_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df$stkrcort_d_9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
